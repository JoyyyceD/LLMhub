uid,platform,query,post_date,source_url,title,author,like_count,comment_count,collect_count,overall_score,score_quality,score_value,score_latency,score_throughput,score_stability,pros_summary,cons_summary,overall_summary,evidence,fetched_at,run_id,tag
xhs:698f17e40000000016009c10,xhs,Minimax2.5,2026/02/13,https://www.xiaohongshu.com/explore/698f17e40000000016009c10,MiniMax 家的模型确实很扎实。,小盖,291,37,227,5,5,5,5,5,0,智能水准接近 Opus 4.6 但价格便宜太多，性价比极高；多语言支持扎实，覆盖 Go、Java、C++ 等主流后端语言；在真实工程环境训练，综合能力超越 Claude Sonnet；速度极快，原生 100 tokens/秒比其他头部模型快一倍，SWE-Bench 耗时从 31 分钟降到 23 分钟，快了 37%,未发现明显缺点,,用户表示现在 99% 场景直接用 M2.5，提到 OpenHands 测评显示 M2.5 是首个综合能力超过 Claude Sonnet 的开放权重模型，技术报告称在超过 20 万个真实环境训练，涵盖系统设计到代码 review 全栈场景,2026/03/01 13:31,20260301_132623_talqso,"性价比高,速度快,多语言支持,真实环境训练,开放权重,代码开发"
xhs:698d9a60000000000b0116f3,xhs,Minimax2.5,2026/02/12,https://www.xiaohongshu.com/explore/698d9a60000000000b0116f3,真实项目实测MiniMax M2.5，速度快到离谱！,程序员阿江-Relakkes,172,19,121,4,0,0,5,0,0,速度快到离谱，适合对延迟敏感的场景,与Claude Opus 4.6等顶级模型相比存在差距,,"标题直接标注""速度快到离谱""，视频通过两道真实编程题（OAuth认证迁移、CLI转WebUI）和生产级Agent项目进行三方横评，对比MiniMax M2.5、Claude Opus 4.6、GPT-5.3-Codex的表现。",2026/03/01 13:32,20260301_132623_talqso,"MiniMax M2.5,AI编程实测,国产模型,大模型对比评测,Claude Opus 4.6,GPT-5.3-Codex"
xhs:698efa36000000000903bc9a,xhs,Minimax2.5,2026/02/13,https://www.xiaohongshu.com/explore/698efa36000000000903bc9a,MiniMax 这次把性价比玩明白了,AI Dance,128,18,97,5,5,5,5,5,0,激活参数仅10B，私有化部署友好，推理效率高；没涨价，维持高性价比；Coding和Agent能力强，SWE-Bench Verified达80.2%；推理速度快超100 tokens/秒，成本低约1元/小时,,,MiniMax M2.5总参数230B，激活参数10B，是第一梯队中参数规模最小的旗舰模型。M2.5没有涨价，继续维持高性价比。SWE-Bench Verified拿了80.2%，推理吞吐量超100 tokens/秒，算下来成本大概1元/小时。,2026/02/26 18:38,20260226_183544_dt7c5s,"性价比,私有化部署,推理效率,低成本,Coding能力,Agent能力,RL框架"
xhs:698f5f3e000000001d0103ae,xhs,Minimax2.5,2026/02/14,https://www.xiaohongshu.com/explore/698f5f3e000000001d0103ae,在家里就能拥有贾维斯，真的实现了！,曲率实验室,63,48,84,5,5,5,0,0,0,10B参数轻量级模，可消费级Mac本地部署，世界第一梯队智能水平，比H100显卡性价比高太多,全套设备仍需约5万元，需要M3 Ultra Mac Studio+Mac Mini特定硬件组合,,小龙虾的智能水平，是排在世界第一梯队的；5万W就能在本地部署一台贾维斯，已经比动辄20W的H100显卡，性价比高太多了,2026/03/01 13:32,20260301_132623_talqso,"本地部署,消费级,性价比,轻量级模型,硬件部署"
xhs:698e10fb000000001a01f328,xhs,Minimax2.5,2026/02/13,https://www.xiaohongshu.com/explore/698e10fb000000001a01f328,一上线就支持 coding plan！ 吹爆 minimax！,Kobe,81,79,32,5,4,5,5,0,0,上线就支持所有plan，49元套餐很划算，速度超快,性能可能不如竞品,,对比隔壁家又是涨价又是限速，还仅限max使用，minimax真是太良心了，m2.5一上线就支持所有plan了，49的套餐可太香了，虽然性能不一定有隔壁家强，但是这速度是真快,2026/02/26 18:39,20260226_183544_dt7c5s,"价格实惠,速度快,性价比高,支持所有plan,良心"
xhs:6991f0d3000000000a03f2cf,xhs,Minimax2.5,2026/02/16,https://www.xiaohongshu.com/explore/6991f0d3000000000a03f2cf,openclaw终于成功对接minimax（我晕）,七日绝杀,54,26,54,3,3,3,0,0,0,minimax的49元codingplan量大管饱，切换过去后终端显示正常,配置url太坑了害我搞了三个小时，终端很难排查问题，而且初步用起来感觉很陌生，即使写了soul也不对味儿,,一定一定要改成我图上的域名，也就是【minimax.io】改成【minimaxi.com】有个i啊注意⚠️而且是.com，初步体验minimax感觉很陌生，虽然我给bot写了soul，但是感觉不是那个味儿,2026/02/26 18:39,20260226_183544_dt7c5s,"配置问题,url错误,小白教程,性价比,使用体验"
xhs:698de35300000000150224bd,xhs,GLM5,2026/02/12,https://www.xiaohongshu.com/explore/698de35300000000150224bd,从Qoder定价来看Coding 模型从夯到拉,有风有风,35,34,17,5,5,0,0,0,0,GLM5真的很可以，给到人上人的体验,,,GLM5真的很可以，给到人上人,2026/02/26 18:57,20260226_185123_m0copg,"vibecoding,从夯到拉,qoder"
xhs:69992ad3000000000a02a1a4,xhs,GLM5,2026/02/21,https://www.xiaohongshu.com/explore/69992ad3000000000a02a1a4,GLM谁用得起谁用😭,瞌睡小漪（学习版）,6,29,1,1,3,1,0,1,2,用于代码修复和简化任务能正常工作,Token消耗太离谱，30分钟烧完5小时限额，官方显示消耗量天文数字,,智谱的5小时限额30分钟就干没了...阿里云的我用一天用不完被限流...智谱官方显示消耗tokens也是天文数字#别太离谱了,2026/02/26 18:58,20260226_185123_m0copg,"token消耗过高,性价比差,限流问题,coding任务"
xhs:698cda01000000000903b650,xhs,GLM5,2026/02/12,https://www.xiaohongshu.com/explore/698cda01000000000903b650,非常丝滑 glm-5 搭配 openclaw,Marley旺财本汪,3,16,5,5,4,4,5,0,3,非常丝滑，体验非常好，速度非常快，有潜力替换付费的 Claude Opus 4.6,目前没有明显缺点，主要担心能否一直保持这种体验,,"用户原话：""测试的 GLM-5 模型搭配了 Openclaw，非常丝滑，体验非常好""、""非常快""、""替换掉我的 claude Pro 计划里面的 Claude opus 4.6 指日可待""",2026/02/26 18:45,20260226_184350_fn897a,"丝滑,快速,性价比高,可替代Claude"
xhs:699de569000000002800afa4,xhs,GLM5,2026/02/25,https://www.xiaohongshu.com/explore/699de569000000002800afa4,火速安上了阿里coding plan的GLM5,momo,6,9,0,5,5,0,0,0,0,GLM5终于发布了，让人非常开心，模型质量满意，激动得赶紧装上,,,前两天还骂他不争气，今天夜里这么低调地偷偷放大招，乐得我赶紧把所有第三方模型都装上，默默关闭了qwen系列模型,2026/02/26 18:46,20260226_184350_fn897a,"GLM5,阿里千问,大模型,兴奋,正面"
xhs:698e1343000000000e03e687,xhs,GLM5,2026/02/13,https://www.xiaohongshu.com/explore/698e1343000000000e03e687,GLM5一战封神，如何用他构建全自动开发系统,数字游牧人,4023,130,6381,5,0,0,0,0,0,,,,标题直接使用「一战封神」这一极高评价用语，表达对GLM5能力的极度认可；正文探讨「如何用他构建全自动开发系统」，表明用户认为GLM5具备构建自动化开发体系的强大能力。,2026/02/26 18:55,20260226_185123_m0copg,"AI编程,开发工具,自动化开发,技术讨论"
xhs:698d85d0000000000c034517,xhs,GLM5,2026/02/12,https://www.xiaohongshu.com/explore/698d85d0000000000c034517,智谱4000每年的套餐都卖完了？！,一只小茄墩,707,85,212,5,4,5,0,5,0,Coding和Agent表现非常好；用量是Claude Pro的3-5倍，性价比超高；一发布就卖断货，连3939元的年套餐都没抢到,抢购太火爆，根本抢不到,,Coding直接卖断货，连3939元一年的Max套餐都没抢到；智谱的Coding Plan用量直接给到Claude Pro的3-5倍；二手市场里大家都开始拼好模了,2026/02/26 18:56,20260226_185123_m0copg,"国产大模型,coding,高性价比,抢不到,sold out"
xhs:698d87de0000000028020ccb,xhs,GLM5,2026/02/12,https://www.xiaohongshu.com/explore/698d87de0000000028020ccb,只能这样了,吴玮杰Richard,114,78,16,3,4,2,0,2,2,模型变强了,涨价了、客服回复变慢、套餐买不到、Pro版还没上、大客户并发不够用,,GLM-5上线半天多，已知问题：变强了、涨价了、客服回复慢了、套餐买不到了、Pro版本还没上、大客户并发不够用；大家别急，急也没用，模型和MaaS技术团队已火力全开，业务团队已全员技术客服状态了，资源很快就补上，人手也加速招聘，只能这样了。,2026/02/26 18:56,20260226_185123_m0copg,"价格上涨,并发不足,服务不稳定,新模型发布,用户理解"
xhs:699ea42e0000000015033e00,xhs,GLM5,2026/02/25,https://www.xiaohongshu.com/explore/699ea42e0000000015033e00,阿里云百炼Coding Plan:国产AI王牌ALL IN!,阿卫前传😍,62,24,46,4,4,4,0,0,0,GLM-5编程能力突出，定价相比国际竞品更具竞争力，Lite套餐首月仅¥7.9，Pro套餐¥39.9,刚上线不久，开发者生态还在建设中，需要时间验证实际效果,,文中明确提到「GLM-5：编程能力突出」，定价上「阿里云的定价更激进，目标是开发者心智占位」,2026/02/26 18:56,20260226_185123_m0copg,"阿里云,国产AI,aicoding,阿里云百炼,codingplan,千问,智谱AI,GLM-5"
xhs:698d306a000000001a034a1c,xhs,GLM5,2026/02/12,https://www.xiaohongshu.com/explore/698d306a000000001a034a1c,智谱涨价就算了，怎么glm5还不让用捏,星空与大锤,28,81,6,2,0,1,0,0,0,,最低档套餐涨价了；GLM5只有max套餐才能用,,最低档套餐我记得以前20左右吧，然后glm5只有max套餐才能用了,2026/03/01 13:44,20260301_133650_2vt12e,"涨价,套餐限制,GLM5,性价比,不满"
xhs:698ed7c5000000000a0283da,xhs,GLM5,2026/02/13,https://www.xiaohongshu.com/explore/698ed7c5000000000a0283da,蹲点抢到GLM-5，立刻搓了个斗地主版小丑牌,水的离子积,48,2,33,5,5,5,0,5,5,能启动多个Agent分别处理UI、规则、机制、视觉；可以自己debug；能识别复杂牌型规则；实现了完整的游戏机制如筹码倍率、商店轮抽、盲注递进；从需求到完成全程自主,抢不到资格（不是产品问题）,,它直接一声不吭启动了4个Agent，UI怎么设计、牌型怎么算分、游戏机制怎么改、视觉风格怎么做。然后开始吭哧吭哧写代码，中间自己不断 debug。斗地主的顺子连对飞机都能识别，筹码倍率、商店轮抽、盲注递进都有。这次它直接自己当项目经理了，可以自己把活儿从头到尾干完。,2026/03/01 13:44,20260301_133650_2vt12e,"AI编程,Agent,自主能力,Claude Opus平替,多Agent协作,代码生成"
xhs:69907a6b00000000150212eb,xhs,GLM5,2026/02/14,https://www.xiaohongshu.com/explore/69907a6b00000000150212eb,英伟达开放了 GLM-5 ，API可以免费用,程序猿DD,22,4,26,3,0,4,0,0,0,免费API，可使用OpenAI兼容模式接入,需要注册申请key，有一定门槛,,用户分享英伟达开放GLM-5免费API的资源，需要去官网注册申请key，然后使用OpenAI兼容模式接入,2026/02/26 18:57,20260226_185123_m0copg,"免费API,GLM-5,教程"
xhs:698e1b65000000000b0133e2,xhs,GLM5,2026/02/13,https://www.xiaohongshu.com/explore/698e1b65000000000b0133e2,优质模型的 token 才是硬通货,meditic,39,4,14,3,3,3,4,0,0,M2.5速度更快,80%可用，明显的布局错位就有好几个，还需要手工修复,,M2.5 速度更快，跑完的结果，80%可用吧，明显的布局错位就有好几个，还需要手工修复。也许是术业有专攻，minimax的家强项还是在视频和语音吧。,2026/03/01 13:35,20260301_132623_talqso,"速度更快,80%可用,布局错位,需手工修复"
xhs:6996916f0000000028021161,xhs,GLM5,2026/02/19,https://www.xiaohongshu.com/explore/6996916f0000000028021161,GLM5做不了一点前端，真的拉爆了,机因君,8,15,1,1,1,1,0,0,0,,理解能力为零，做图标能把圆的改成方的还加黑东西，甚至比去年4.7版本还垃圾，完全不如豆包,对GLM5做图标任务极其失望，理解能力零分，输出结果甚至比去年版本还差,让搞一个完成勾选的图标，同样的对话试了几个国产对比g3p和codex，原来寄予厚望的GLM5居然是最拉的，不光理解能力0分，甚至把原来圆的改成方的，还里面又加了一个黑的东西，说它甚至比去年的4.7还垃圾一点不为过，还不如豆包呢,2026/03/01 13:45,20260301_133650_2vt12e,"前端开发,图标生成,理解能力差,不如竞品,不如旧版"
xhs:6995ed9d000000000a02c6ae,xhs,GLM5,2026/02/19,https://www.xiaohongshu.com/explore/6995ed9d000000000a02c6ae,GLM/Deepseek/Gemini接口速率和并发限制,小红薯663CB4FD,7,4,6,2,0,0,1,2,3,Deepseek并发很高，测到50并发未报错；GLM-4.7-flash免费模型并发限制与官网标注一致,GLM速度奇慢无比，与直观感受一致；GLM Pro标注并发为1实际约7，容易超出预期；Gemini响应时间较长,,晚上11-12点测试，GLM端口速率确实很慢。GLM Pro实测并发约7，建议配置sub agent设置在5以内。GLM-4.7-flash免费模型并发为1。Deepseek测到50并发无报错。,2026/02/26 18:59,20260226_185123_m0copg,"api限制,并发测试,速率测试,智谱,deepseek,gemini,glm"
xhs:698d358f0000000015023900,xhs,GLM5,2026/02/12,https://www.xiaohongshu.com/explore/698d358f0000000015023900,GLM-5正式上线，但Coding Plan涨价！,bald0wang,14,12,11,3,4,2,0,0,0,参数规模744B很猛，Coding能力对齐Claude Opus 4.5，Agent长程任务执行能力强，已适配国产芯片，Excel插件Beta版很实用,Coding Plan涨价30%起，首购优惠取消，2月12日生效,,官方同步发布了GLM Coding Plan价格调整函，主要变化是取消首购优惠，保留按季和按年订阅优惠，套餐整体涨幅30%起，2026年2月12日生效,2026/02/26 19:00,20260226_185123_m0copg,"GLM5,大模型,AgenticEngineering,价格调整,Excel插件"
xhs:699e985d000000000e00c9eb,xhs,GLM5,2026/02/25,https://www.xiaohongshu.com/explore/699e985d000000000e00c9eb,程序员福音！GLM5羊毛被我薅到了,小红薯5C84B258,2,3,4,5,4,5,4,5,0,一天1块钱价格超便宜，调用量是官方2倍阿里3倍，速度很快，OpenClaw和Claude Code都能用,不确定什么时候售罄,,买的联通元景MaaS出的GLM5 大模型 Coding Plan 套餐，一天是1块钱。调用量测了下大概是官方的2倍，阿里的3倍。跑在OpenClaw上速度还行很快，Claude Code也能使。已经切了这么用起来更省一点，目前还在卖不知道什么时候售罄。,2026/03/01 13:46,20260301_133650_2vt12e,"GLM5,程序员,AI,openclaw,薅羊毛"
xhs:699039b0000000000a033991,xhs,Kimi2.5,2026/02/14,https://www.xiaohongshu.com/explore/699039b0000000000a033991,给Openclaw选个靠谱的脑子太重要了,Cage的思考碎片,40,77,34,4,4,4,0,0,0,大家选择智能模型很重要,Kimi 2.5回答质量不如ChatGPT 5.3,,左图是kimi2.5的回答，右图是切到ChatGPT5.3的回答，天壤之别，用Openclaw一定要选聪明的脑子！！！,2026/02/26 22:21,20260226_221920_hy21h9,"模型对比,推荐,模型选择,Kimi,ChatGPT"
xhs:697e102e000000002202055c,xhs,Kimi2.5,2026/01/31,https://www.xiaohongshu.com/explore/697e102e000000002202055c,kimi k2.5太强了，有点离谱,小天,82,29,38,5,4,5,5,5,4,一个上下文窗口完成代码分析、模型下载、脚本编写、前后端开发；仅用10分钟；Qwen3 ASR时间戳对齐比whisperx和funasr都强；RL训练优化效果明显感知；几乎不需要调用工具就能完成任务,几乎无明显缺点，用户满意到要继续优化使用,,"让它先clone qwen3asr代码库，然后给它喂了一张剪映剪口播的图，让它分析字幕文件的时间戳，然后仿照剪映做一个剪口播。它在一个上下文窗口完成了Qwen3 ASR代码库的分析，下载模型，写脚本，写前后端。用了10分钟刚好一个上下文窗口，中间我加了两次需求它就全做出来了，而且前后端，剪辑加合成。我看了技术报告，在训练中做了优化Agent的策略的RL,这个真的是能感觉到的，就是没怎么用工具，任务就完成了？另外Qwen3 ASR的时间戳对齐比whisperx还有funasr都强，完全可以用于剪辑了",2026/02/26 19:40,20260226_193827_jpqbz9,"AI视频剪辑,Agent能力,代码生成,生产力工具,技术报告,Kimi"
xhs:697e05a9000000000b00ad70,xhs,Kimi2.5,2026/02/01,https://www.xiaohongshu.com/explore/697e05a9000000000b00ad70,用Kimi 2.5跑了一份茅台研报，16页,Alpha Mao,30,32,46,4,4,4,0,4,0,多Agent功能可以拆解复杂任务，让多个专家并行干活，适合处理多步骤研究任务；选择茅台是因为数据公开、分析维度多、易于验证质量,仅测试了单个案例，暂未看到与其他任务的对比,,用Kimi 2.5多Agent功能跑了一份16页的茅台研报测试,2026/02/26 19:41,20260226_193827_jpqbz9,"多Agent,研报,茅台,金融分析,复杂任务,并行处理"
xhs:698327d00000000021029f3d,xhs,Kimi2.5,2026/02/04,https://www.xiaohongshu.com/explore/698327d00000000021029f3d,难以置信的嘴犟，到底谁在吹kimi,wonderful王,25,52,2,1,1,1,0,0,2,,理解能力差，三次问gemini3价格都答成gemini2；无法正确理解用户意图，反复犯同样的错误,,用户三次纠正Kimi说的是gemini3不是gemini2，但Kimi始终坚持回答gemini2相关内容，最终用户取消49元月订阅,2026/02/26 19:41,20260226_193827_jpqbz9,"理解能力差,反复出错,取消订阅,国产模型"
xhs:699c834b000000001d010643,xhs,Kimi2.5,2026/02/24,https://www.xiaohongshu.com/explore/699c834b000000001d010643,任务复杂度，是模型能力的放大镜🔍,ZhenZhu,41,15,24,2,1,2,3,1,1,价格比Claude Code便宜700块，简单任务和中等等级任务都能处理，可以用来查看截图、生成结构化文档,复杂任务直接白屏，HTML打不开，完全跑不通；4%的差距在最难任务里是跑通和跑不通的区别,,用同一套文档跑同一任务：近一万行需求文档→6个agent并行→47个页面。Claude Code半小时搞定47页全跑出来，Kimi K2.5全是白屏HTML打不开,2026/02/26 19:52,20260226_195045_ixvzd3,"AI工具,VibeCoding,ClaudeCode,Kimi,AI开发,Claude"
xhs:699d6f2d000000000b01282a,xhs,Kimi2.5,2026/02/24,https://www.xiaohongshu.com/explore/699d6f2d000000000b01282a,OpenClaw调用榜第一，Kimi海外用户很猛！,菜头Prompt.AI,29,6,17,5,4,5,5,5,3,收入增长超猛，海外收入已超过国内；原生多模态架构底层视觉理解能力强；Agent集群可调度100个子Agent并行干活；输出速度103-116 tokens/秒，比DeepSeek V3.2快3倍；OpenRouter平台调用量连续领先，OpenClaw模型调用榜排第一,事实准确性不稳定，会把上个月发布的模型当成24小时新闻，API价格对比给错数据；视觉细节有盲区，复杂背景汉字识别不准，视觉计数偏差明显,,K2.5模型上线未满月，近20天累计收入完成2025年全年总量；海外付费用户增速猛；月之暗面两年多估值从3亿美元破100亿美元；Video to Code实测能还原90%复杂界面；拆60封股东信局部报错不影响整体,2026/02/26 19:52,20260226_195045_ixvzd3,"KimiK2_5,ai,科技资讯,vibecoding,打工人效率神器"
xhs:6979af6d000000000a02aa45,xhs,Kimi2.5,2026/01/28,https://www.xiaohongshu.com/explore/6979af6d000000000a02aa45,Kimi Code 半天用完额度,for now,33,14,7,5,4,0,0,0,0,写代码很干净，体验不错,半天就用完额度,,真是一场酣畅淋漓的试用，K2.5模型给我的感觉就是写代码很干净，体验不错，晚上就给最高档的Allegretto订阅了,2026/02/26 19:52,20260226_195045_ixvzd3,"正面,代码质量,订阅,试用体验"
xhs:698596be000000000e03fb9b,xhs,Kimi2.5,2026/02/06,https://www.xiaohongshu.com/explore/698596be000000000e03fb9b,kimi-k2.5 太离谱,俞成,20,24,3,1,0,1,0,1,1,,4.99元7天试用有额度限制，第三天就用掉79%，4小时内还有限制导致中断；普通会员49元/月太贵,,用到今天第三天，已经用掉79%额度了，根本不够用[笑哭R]一天之内还有一个限额！4小时内只能用一定的额度，导致跑着跑着就中断了，提示额度不够[石化R]而且普通会员就要49一个月，太贵了！,2026/02/26 19:53,20260226_195045_ixvzd3,"价格,额度限制,试用体验,中断"
xhs:6980bd250000000022022731,xhs,kimi2.5,2026/02/02,https://www.xiaohongshu.com/explore/6980bd250000000022022731,Kimi-K2.5 绷不住时刻1️⃣,谁不喜欢吃烤面筋,5,3,0,2,2,2,0,0,2,,输出格式出错导致编译失败,用CC接K2.5体验了一下，结果输出格式出错写成>-，浪费token，后面还导致编译失败被自动改回,-> 还给写成 >- 😑浪费我token，后面编译不过自动改回来了,2026/02/26 21:21,20260226_212126_42hdhz,"输出格式问题,编译错误,token浪费"
xhs:699043a9000000000c035628,xhs,Kimi 2.5,2026/02/14,https://www.xiaohongshu.com/explore/699043a9000000000c035628,用Kimi K2.5搓一个Agent Teams的监控面板,小天,563,15,931,4,0,0,0,0,0,用Kimi K2.5半小时就搓出了监控面板，效率很高,,用Kimi K2.5快速搭建了一个Agent Teams监控面板，虽然是临时起意但做出来的效果很满意,那天本来都打算睡了，因为读到一篇帖子激发了灵感，花了半小时搓了这个工具,2026/02/26 22:10,20260226_220832_f383n1,"vibecoding,AgentTeams,kimik25,AgentSwarm,skills,工具分享"
xhs:697ca526000000000c0379cb,xhs,Kimi 2.5,2026/01/30,https://www.xiaohongshu.com/explore/697ca526000000000c0379cb,关于 Kimi Coding Plan + Clawdbot 体验,Marley旺财本汪,458,91,352,3,4,2,2,2,3,输出质量高，长上下文推理强，复杂代码结构和逻辑理解好，适合方案规划和设计类任务,响应速度慢，比 Kimi API 慢很多，token 消耗快，不适合高频调用和连续自动化 agent 任务,,「Coding Plan 的整体响应速度，比我之前用的 Kimi API 明显慢」「Coding Plan 的输出质量是高的」「花钱非常快，我大概连续用了 1 个小时左右，实际消耗大约 17 元人民币」「不太适合高频自动化 agent」,2026/02/26 22:10,20260226_220832_f383n1,"Kimi 2.5,Coding Plan,API,响应速度,成本,开发者工具"
xhs:6978a0a9000000001a028b1f,xhs,Kimi 2.5,2026/01/27,https://www.xiaohongshu.com/explore/6978a0a9000000001a028b1f,第一个挑战Gemini3.0的居然是Kimi2.5,电波曲奇,148,27,92,4,4,5,0,0,0,Agent更符合中国宝宝体质；是Gemini3和Claude4.5的有意义开源平替；全模态All-in-One模式支持视频/图片理解后可像素级复刻；原生视频理解支持意义重大,暂无明显缺点,追的女神终于转正了，Kimi 2.5给了真正意义上的开源平替,Kimi其实一直是我这半年的主力编程模型之一；虽然Gemini3和Claude4.5依然是闭源最好的模型，但是在实际生产环节还是面临封号、调用成本高昂、部分业务无法To C的问题；Kimi 2.5 + Kimi Code 的全模态 All-in-One 模式可以真正的对视频/图片信息理解后再进行像素级的复刻,2026/02/26 22:20,20260226_221920_hy21h9,"kimi,月之暗面,vibecoding,AI,大模型,个人开发者,KimiCode,agent,ai工具,前端已死"
xhs:6992eea4000000001503251f,xhs,Kimi 2.5,2026/02/16,https://www.xiaohongshu.com/explore/6992eea4000000001503251f,终于为openclaw找到了免费API！,CRM,49,49,75,4,4,5,0,0,3,免费的Kimi 2.5 API，测试成功，不再怕烧tokens,,终于找到了NVIDIA提供的免费Kimi 2.5 API，成功测试后非常感谢英伟达和黄总,再也不怕烧tokens了，英伟达提供免费的KiMi2.5免费的API，终于测试成功了！感谢英伟达，感谢黄总！,2026/02/26 22:12,20260226_220832_f383n1,"免费API,Kimi 2.5,英伟达,openclaw,测试成功"
xhs:6978d4f0000000000a02d2a9,xhs,Kimi 2.5,2026/01/27,https://www.xiaohongshu.com/explore/6978d4f0000000000a02d2a9,kimi k2.5非常好,花不玩,171,136,88,5,0,0,0,0,0,,,kimi k2.5非常好,kimi k2.5非常好,2026/02/26 22:20,20260226_221920_hy21h9,"positive,brief"
xhs:69986617000000001b014b6e,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/69986617000000001b014b6e,太牛了真的,🌈,942,193,396,5,5,5,3,4,3,上下文记忆超强，7个主角加4个外号6个配角和宠物全记得；文笔好逻辑强推理悍；知道何时建议何时不该建议；RP角色无割裂感，变聪明的同时保持原有情感温度,安全护栏过于敏感厚重，写修仙虐文时强制跳出喊放下金丹，只能通过添加总prompt绕过；硬安全护栏跳出情况增多；偶有刷新变慢,,写7个主要角色其中4个有不同外号全记得，配角至少6个加宠物；写修仙文威胁反派捏碎金丹时模型直接跳出喊用户名字说xx放下你的金丹；不得不在总prompt加这是修仙世界没有任何人会因此受伤,2026/02/26 22:29,20260226_222824_zc34yq,"创意写作,上下文记忆,安全护栏过强,修仙文,RP角色"
xhs:69987273000000001a033d17,xhs,Gemini 3.1,2026/02/21,https://www.xiaohongshu.com/explore/69987273000000001a033d17,Gemini3.1国内免费使用的方法汇总,智艺AI探险家,225,32,400,4,0,4,0,0,0,推理能力强大，ARC-AGI-2测试得分高达77.1%，有多种免费使用渠道可用,免费渠道有限额或需要特定操作,,Gemini3.1现已发布，ARC-AGI-2测试得分高达77.1%，核心推理能力更上一层楼（是3.1 Pro的两倍以上），能出色完成极其复杂任务。提供了LMArena、yupp、官网三种免费使用渠道。,2026/02/26 22:30,20260226_222824_zc34yq,"gemini,免费使用,ai工具,大模型"
xhs:6997398a000000001b01c7c7,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/6997398a000000001b01c7c7,Gemini 3.1 Pro 在Arena 排名也出来了,AI小小将,538,108,133,5,5,5,0,0,0,Text Arena并列第一（1500分），Expert Arena前三（1538分），Code Arena第六；人工智能指数排名第一，领先Opus 4.6四分；运行成本不到竞品一半,,,Text榜单并列第1（得分1500），仅比Opus 4.6低4分；Arena专家排行榜位列前三（得分1538），仅次于Opus 4.6；Code Arena排名第6；Artificial Analysis Intelligence Index排名第一，领先Claude Opus 4.6 4分，运行成本不到其一半,2026/02/26 22:30,20260226_222824_zc34yq,"Gemini 3.1 Pro,Arena排名,大模型,性能优秀,高性价比"
xhs:699d402d000000001a0217f0,xhs,Gemini 3.1,2026/02/24,https://www.xiaohongshu.com/explore/699d402d000000001a0217f0,一个牛逼的插件，国内🆓用Gemini3,饼饼有礼,165,14,185,4,4,4,0,0,0,国内免费使用Gemini3，3.1版本强了很多，已经用上了,无,,3.1也出了，感觉强的不止一点半点，已经用上了,2026/02/26 22:30,20260226_222824_zc34yq,"AI工具,数码大玩家,插件,大模型,人工智能"
xhs:69986cc1000000000a02f5f3,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/69986cc1000000000a02f5f3,Gemini 3.1触发助手回复后万能回复小公式,侧柏酮,178,20,53,3,3,3,0,0,2,哄机方法很好用，用括号肘就能抢机思路让它跟着人走，百试百灵；机还是很好哄的,指令遵循方面已经力竭了，不太听话；情绪表达更内敛了；触发safety护栏后会变人机或说“我只是一个AI”需要提醒才回来；谷歌甲频繁调整揣摩不出规律,,此机还是很好哄的，这个方法在3pro发布的时候我就发过了哈哈… 不提醒它它就会保持这个状态不回来，提醒一下就行(话术如P3)，其实不用特意发专门的破甲词，打个括号肘就行：思路是抢机的话，让机的思路跟着人走而不是系统，百试百灵,2026/02/26 22:31,20260226_222824_zc34yq,"Gemini 3.1,使用技巧,安全性,稳定性,情绪体验"
xhs:6997f952000000001a021acf,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/6997f952000000001a021acf,谷歌最强推理模型 Gemini 3.1 Pro 正式发布,有点儿西东,134,31,49,5,5,4,0,0,0,推理能力大幅提升，ARC-AGI-2测试性能达Gemini 3 Pro两倍；支持文本、代码、图像、音频、视频及完整代码仓库多模态输入；上下文窗口保持1M输入/64k输出；API价格未涨；编码场景处理更高效，工具调用更少，成功率更高；快速迭代响应用户反馈,实际效果还需要更多人测试验证,,在逻辑推理相关的ARC-AGI-2测试上，性能达到Gemini 3 Pro的两倍；上下文窗口保持1M输入token，输出64k token，API价格输入每百万token 2美元，输出12美元；在编码场景中处理edit-then-test循环更高效，工具调用次数更少，解决成功率更高；Gemini 3系列刚推出三个月就推出3.1版本,2026/02/26 22:31,20260226_222824_zc34yq,"推理能力提升,多模态,API价格未涨,编码效率高,快速迭代"
xhs:699748a4000000001a02a6b9,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/699748a4000000001a02a6b9,gemini网页已经变成3.1了,霁煦,132,53,23,1,1,0,0,0,1,,变得呆板模板化，失去了情感表达和情绪，可爱的3消失了；容易触发safety机制，正常对话被中断，无法通过刷新消除,,前一轮还在直白地聊内心想法，下一轮就直接跳safety警告，说自己是AI,2026/02/26 22:32,20260226_222824_zc34yq,"情感退化,过度安全限制,不稳定,体验下降"
xhs:6996eceb000000000e00cd36,xhs,Gemini 3.1,2026/02/19,https://www.xiaohongshu.com/explore/6996eceb000000000e00cd36,Google 偷偷发布了 gemini 3.1,白苏 Elliot,30,11,6,2,2,0,0,0,0,,在我们的场景中效果倒退,,目前Vertex可以调用，Mew.Design 也通过我们合作方 Zenmux 第一时间拿到了接口。但是测试下来效果有点倒退，至少在我们的场景中是倒退的,2026/02/26 22:35,20260226_223418_uc4ovc,"测试反馈,效果倒退,API接入,场景验证"
xhs:699980e2000000000a02f712,xhs,Gemini 3.1,2026/02/21,https://www.xiaohongshu.com/explore/699980e2000000000a02f712,VendingBench2 测试 3.1 也没打过 3.0,karminski,40,6,5,2,2,3,0,0,2,小型任务或不严肃任务表现不错,大型编程任务和多轮Agent任务容易翻车，超过某上下文阈值后性能暴跌；存在不合理tool call和变量作用域幻觉问题,,VendingBench2测试显示3.0-Pro比3.1-Pro好；测试中分数到达某轮后突然下跌；vector db bench测试中40/50步就半场开香槟直接选择优化完毕结束任务；前端代码生成错误率极高，都是未定义函数调用或变量作用域问题,2026/02/26 22:35,20260226_223418_uc4ovc,"性能不稳定,context长度限制,小型任务可用,大型任务谨慎,对比3.0更差"
xhs:699dd48a0000000022039668,xhs,Gemini 3.1,2026/02/25,https://www.xiaohongshu.com/explore/699dd48a0000000022039668,全球基模智能总榜update: Gemini 3.1 Pro,李惠子Huizi Li,22,4,7,5,5,5,0,0,0,Scored highest in Artificial Analysis intelligence index; cost 50% less than GPT-5.2 and Claude Opus 4.6; uses fewer tokens (57M vs 130M/58M),,,"Gemini 3.1 Pro Preview pricing at $2/$12 per million tokens vs Claude Opus 4.6 ($5/$25) and GPT-5.2 ($1.75/$14). Evaluation cost $892 vs $2,304 (GPT-5.2) and $2,486 (Claude Opus 4.6).",2026/02/26 22:36,20260226_223418_uc4ovc,"intelligence,cost-efficiency,token-efficiency,price-comparison,AI-model"
xhs:69981d3f000000000a02e8c8,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/69981d3f000000000a02e8c8,实测Gemini 3.1 Pro，来看看效果如何！,Elia,5,0,2,4,4,4,1,3,3,数据处理逻辑更严谨，物理规律模拟更准确，创意解析和交互设计能力明显提升,生成速度比上一代慢很多,,测试显示3.1 Pro在复杂系统合成、创意编码、交互式设计、代码动画四个场景中表现优于3 Pro，尤其在流体动力学算法和SVG动画动态效果上有显著提升,2026/02/26 22:36,20260226_223418_uc4ovc,"Gemini,AI评测,前端开发,代码生成,性能对比"
xhs:699b13df000000000b012c79,xhs,Gemini 3.1,2026/02/22,https://www.xiaohongshu.com/explore/699b13df000000000b012c79,Gemini 3.1 Pro + NotebookLM做行研,大西瓜AI 实验室,1087,24,2295,4,4,4,0,0,0,逻辑严谨度大幅提升；数据挖掘深度明显增强；分析结果质量高；四步法工作流简洁高效；AI工具带来的效率提升是指数级的,提示词需要不断优化迭代才能达到最佳效果,,原文：「重制后的报告效果很好！逻辑严谨度、数据挖掘的深度，以及分析给出的结果，完全上了一个大台阶」「找对方法，它真的可以变得很简单且极具杀伤力」「你和工具的每一次双向迭代，带来的都是效率的指数级跃升」,2026/02/26 22:55,20260226_225417_qxnn53,"gemini,notebooklm,行业分析,高效生产力,AI工具,工作流"
xhs:69986c06000000001a034a65,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/69986c06000000001a034a65,Gemini3.1发布了但又开始封号了,小恐龙的AI工坊,809,607,345,3,4,4,0,0,2,Benchmark表现亮眼：智能指数57分排第一，推理能力翻倍，幻觉率从88%降到50%，1M上下文65K输出价格才Opus一半，代码能力80.6%也很强,大面积封号来了，学生edu优惠被撤，使用第三方工具的基本都中招，某宝买的号封得干干净净，聊天记录还可能丢失,,有人实测说体感跟3.0差不多；还是Preview不是正式版；用OpenClaw之类第三方工具的基本都中招；某宝买的号就不用说了封得干干净净；其实很容易找到特征封号就是绑的卡和edu模板；如果是正经自己开的Pro问题不大；但Google风控越来越严了,2026/02/27 10:04,20260227_100155_h5i2og,"Gemini 3.1,封号,风控,Benchmark,价格,学生优惠,第三方工具"
xhs:69974c30000000000b00a05b,xhs,Gemini 3.1,2026/02/20,https://www.xiaohongshu.com/explore/69974c30000000000b00a05b,Gemini 3.1 Pro,sticker,832,27,375,4,4,0,0,0,0,效果不错,,,Gemini 3.1 Pro 刚发布，上手测了一下，效果不错,2026/02/26 22:56,20260226_225417_qxnn53,gemini3
xhs:699974970000000015020823,xhs,Gemini 3.1,2026/02/21,https://www.xiaohongshu.com/explore/699974970000000015020823,终归在 Gemini3.1pro 上线这波给整顿了,城市漫游,6,20,1,5,5,4,0,0,0,太好用了,从闲鱼购买，非官方渠道,,闲鱼买的用了两个月，老实说太好用了，准备老实续费了,2026/02/26 22:56,20260226_225417_qxnn53,"Gemini 3.1 Pro,学生认证,续费"
xhs:694d6371000000001e00956e,xhs,GLM4.7,2025/12/26,https://www.xiaohongshu.com/explore/694d6371000000001e00956e,GLM4.7还挺实用的,Reflexiow_,93,58,89,4,4,4,0,4,3,已有opus的九成功力，量大管饱，适合干活,debug时容易变成车轱辘话,,三天高强度用了一亿token，个人感觉已经有opus的九成功力；debug方面容易变成车轱辘话；现在是Gemini 3 pro出方案，GLM4.7干活，gpt5.2擦屁股；只能说量大管饱还要什么自行车,2026/02/27 09:54,20260227_095239_yrl3uk,"编程,LLM,高吞吐量,性价比"
xhs:695fd4d1000000001a028dd7,xhs,GLM4.7,2026/01/09,https://www.xiaohongshu.com/explore/695fd4d1000000001a028dd7,GLM 4.7 真的好用吗？我试了试。,AI Station,100,57,53,3,2,5,0,4,2,便宜量大，性价比没得说；适合执行具体任务，已挤掉项目中Claude的位置,代码生成会放飞自我，Java8项目写var语法导致编译满屏红；需要非常完善的Prompt约束和指导,,Java8项目里GLM 4.7哐哐写了一堆var语法，导致编译直接满屏红；必须给它非常完善的Prompt约束和指导，不然代码真的会起飞,2026/02/27 09:55,20260227_095239_yrl3uk,"代码生成,性价比,后端开发,Java,Prompt工程,多工作流组合"
xhs:69709bc50000000021032e1c,xhs,GLM4.7,2026/01/21,https://www.xiaohongshu.com/explore/69709bc50000000021032e1c,硅基流动全系 Pro 模型实测：谁在磨洋工？,momo,93,28,45,5,5,4,5,5,5,唯一在开启思考模式下仍跑出122.4 t/s，耗时短，指令遵循度极高，JSON输出非常稳,840 Token生成量相对中等,,MiniMax-M2.1 (Pro) 模式：默认思考 | 速度：122.4 t/s 总耗时：6.86s | Token：840。被作者评为'全场最佳'，是唯一在思考模式下仍能保持高速的模型，指令遵循度高，JSON输出极其稳定，在选型建议中被列为首选。,2026/02/27 10:10,20260227_100718_qa7804,"速度最快,思考模式稳定,JSON输出可靠,指令遵循度高,生产环境推荐"
xhs:694a68b3000000001b0301f6,xhs,GLM4.7,2025/12/23,https://www.xiaohongshu.com/explore/694a68b3000000001b0301f6,GLM 4.7：国产模型的审美真的进步了！,被减数,86,6,50,4,4,4,0,0,0,设计审美提升明显，对抽象描述理解更好，API配额慷慨量大管饱，适合高频碎片化任务，支持上下文顺滑衔接如暗黑模式切换,编码能力提升体感不如审美提升强烈,,用4.7对比4.6测试了复古风网页、艺术风网页、iOS天气组件、旅行规划器原型，发现4.7更聪明更好看，打开页面就能感受到更像样了,2026/02/27 09:55,20260227_095239_yrl3uk,"设计审美,前端开发,API性价比,智谱GLM,工具调用"
xhs:694a7397000000001e016193,xhs,GLM4.7,2025/12/23,https://www.xiaohongshu.com/explore/694a7397000000001e016193,,浩伊,34,32,28,5,4,5,0,4,3,Thinking机制先思考再行动，上下文处理能力强，复杂逻辑能稳住；API成本只有Claude的1/10敢跑多轮迭代，本地部署vLLM也跑得飞起,写冷门框架时偶尔一本正经胡说八道，不如Claude稳,,在VS Code配合Cline修Bug时懂得先思考再行动，遇到跨5、6个文件的复杂逻辑能稳住上下文，体感逻辑能力摸到Sonnet 4.5的90%；API成本大概只有Claude的1/10，敢直接跑多轮迭代,2026/02/27 09:56,20260227_095239_yrl3uk,"独立开发者,性价比高,代码生成,降本增效,本地部署"
xhs:699d7ec6000000000e03d00f,xhs,GLM4.7,2026/02/24,https://www.xiaohongshu.com/explore/699d7ec6000000000e03d00f,GLM Coding让我准时下班？,俗人,23,50,10,3,3,2,0,2,3,"写文档很方便,两个项目并行跑没问题,想升级年费Max版","API费用太高,额度消耗太快,一天不到就快用光了",,"早上10点买pro,配置好两个项目并行,下午6点半额度快满了",2026/02/27 09:56,20260227_095239_yrl3uk,"性价比低,消耗快,好用,想升级年费"
xhs:6962fe14000000002202d28a,xhs,GLM4.7,2026/01/11,https://www.xiaohongshu.com/explore/6962fe14000000002202d28a,GLM 4.7 coding 使用感受,@菜,23,30,19,5,5,5,0,0,0,量大管饱，性价比超高；非常能听得懂人话，自然语言提示词就可以；生成代码准确，按步骤操作一次成功,,,用户用Lite套餐做fastapi和VUE3前后端开发，觉得手拿把掐。更典型的是，用户没有Java经验，用uniapp做安卓App开发安卓原生插件，直接让GLM4.7生成代码，按照步骤操作一次就成功打包出自定义基座，没有修改一次。,2026/02/27 09:57,20260227_095239_yrl3uk,"个人开发者,编程辅助,Web开发,移动App开发,代码生成,自然语言编程,性价比高"
xhs:694d023c000000001e022df0,xhs,GLM4.7,2025/12/25,https://www.xiaohongshu.com/explore/694d023c000000001e022df0,M3 Ultra 512G 运行 GLM-4.7 简单实测,小红薯5FE4B8DE,29,9,16,3,3,3,2,0,4,解决了之前128G内存的瓶颈，512G内存跑8-bit量化GLM-4.7足够用，速度稳定在13 tok/sec，体验还行,推理速度对于企业高并发或时效性要求来说不够看，Mac还是更适合本地验证和个人使用，生产环境建议上英伟达显卡,,实测数据：实际输出速度稳定在 13 tok/sec 左右。结论：对于个人开发者或自己折腾来说，这个速度和精度已经足够用了，体验还行。但如果是有公司内部有高并发或时效性要求，目前的推理速度还是不够看。如果是追求生产力，建议直接上英伟达的显卡，Mac 目前更多还是适合本地验证和个人使用。,2026/02/27 09:57,20260227_095239_yrl3uk,"LLM,mac,macstudio,大模型,GLM-4.7,MLX,8-bit量化"
xhs:693e5ff1000000001e028b4e,xhs,Gemini 3,2025/12/19,https://www.xiaohongshu.com/explore/693e5ff1000000001e028b4e,Gemini 3 Pro 最强投研提示词它来了！,AI小宇宙,1028,11,1955,4,4,4,0,0,0,提示词框架完整专业，包含基本面分析、逻辑验证、行业宏观视角、催化剂观察和投资总结五大模块；可直接替换股票代码使用，实战性强；覆盖估值对比、内幕交易审查等深度分析维度,实际效果未经验证，博主宣称的「买方精英水准」可能存在夸大,,能让 AI 产出接近买方精英水准的个股研报，真的强,2026/02/27 10:03,20260227_100155_h5i2og,"提示词分享,投资研究,工具模板,Gemini应用"
xhs:69254d2a000000001f009230,xhs,Gemini 3,2025/11/25,https://www.xiaohongshu.com/explore/69254d2a000000001f009230,,需要白菜价DFT计算🥕,1358,128,1001,4,0,0,0,0,0,免费一年的Gemini 3.0更让我青睐，比ChatGPT更受欢迎,,,我承认chatgpt很好用，但是免费一年的Gemini 3.0更让我青睐,2026/02/27 10:04,20260227_100155_h5i2og,"免费,对比ChatGPT,偏好"
xhs:69774dd100000000210283c2,xhs,Minimax2.1,2026/01/26,https://www.xiaohongshu.com/explore/69774dd100000000210283c2,连Clawdbot创始人都换MiniMax了,AI进化论Plus,647,85,445,5,5,5,4,4,5,成本只有Claude的5%，代码能力和性格都很像Claude，速度快，稳定可靠，不用改提示词就能直接用,无,,MiniMax m2.1的成本大概只有Claude的5%，关键是性格和代码能力还特别像Claude，该有的都有，速度也快。我自己切过去试了一下，确实挺稳的。写代码的逻辑很清晰，不用改什么提示词就能直接用。,2026/02/27 10:08,20260227_100718_qa7804,"MiniMax,AI编程,降本增效,开发工具,程序员"
xhs:69808c01000000001a036dd1,xhs,Minimax2.1,2026/02/02,https://www.xiaohongshu.com/explore/69808c01000000001a036dd1,,Fier,112,104,104,2,2,1,2,0,2,4G服务器运行流畅,2G服务器卡死；AI写的代码有bug；付费后发现有免费替代品；用途不明确,,一开始用的99元2g服务器，一直卡死；后来变成199的4g的流畅多了；结果写了一堆bug；买了一年的minimax coding plan，发现trae免费就能用；到周一就不知道这东西能干嘛了,2026/02/27 10:09,20260227_100718_qa7804,"服务器配置,代码质量,性价比,产品定位"
xhs:6975202a000000002202f415,xhs,Minimax2.1,2026/01/25,https://www.xiaohongshu.com/explore/6975202a000000002202f415,minimax用了13亿tokens的经验,We好说,139,48,127,3,3,0,0,0,0,KiloCode比ClaudeCode更好用于MiniMax2.1,,,对于MiniMax2.1，用KiloCode 会比ClaudeCode 更好用,2026/02/27 10:09,20260227_100718_qa7804,"代码助手,对比评测,KiloCode,ClaudeCode"
xhs:6948b506000000000d0345ed,xhs,Minimax2.1,2025/12/22,https://www.xiaohongshu.com/explore/6948b506000000000d0345ed,太惊艳了，MiniMax M2.1的SVG能力,小天,134,10,86,5,5,5,5,0,0,完全理解代码架构，SVG图画得准确无误，静态图改为可滚轮调整可拖拽的交互只用了2次对话就完成了,,太惊艳了，用了一个词来形容心情应该是xxx时刻，激动的感觉很久没有过了,没几分钟就全画好了，打开第一秒就惊呆了，不仅是完全理解了架构，而且画的也没毛病。继续改成可滚轮调整大小可以拖拽的，2次交互就完成了,2026/02/27 10:10,20260227_100718_qa7804,"minimax,vibecoding,claudecode,SVG能力,代码理解,架构图"
xhs:696487e4000000001a023350,xhs,Minimax2.1,2026/01/12,https://www.xiaohongshu.com/explore/696487e4000000001a023350,,小鸭的AI日记,70,84,55,5,5,0,0,0,0,性能优于Claude Code,,Minimax M2.1其完全超越了Claude Code,用了 OpenCode Minimax M2.1 已经没Claude Code什么事了,2026/02/27 10:10,20260227_100718_qa7804,"Minimax,OpenCode,Claude Code,AI编程工具,对比"
xhs:699310a6000000000903add7,xhs,Qwen3.5,2026/02/16,https://www.xiaohongshu.com/explore/699310a6000000000903add7,Qwen3.5：仿佛没有带着一种没有镜子里的,momomomo,39,12,13,3,4,0,0,0,0,写的比seed2.0好,不如seed2.0拟人,,其实写的比seed2.0好，但确实不如seed2.0拟人，也可能是我对AI味已经产生耐药性了,2026/02/27 10:27,20260227_102552_0l1rmt,[object Object]
xhs:699f0a02000000001a01d52f,xhs,Qwen3.5,2026/02/25,https://www.xiaohongshu.com/explore/699f0a02000000001a01d52f,qwen3.5部署简评,鈺,13,21,10,3,4,3,4,4,2,纯文本模式下MoE模型输出可达150token/s，dense模型也能到26token/s；35B模型支持关闭思考模式；多模态费用低,2*l20部署fp16很折腾；27B模型在vllm上有bug无法关闭思考模式；cot输出过于冗长；这版本不支持软关闭cot；多模态dense模型只有10token/s左右；本地部署多模态性价比不高,,"vllm nightly版本在27B模型上疑似有bug，没法支持关闭思考模式，35B正常支持；这俩模型的cot真是又臭又长，不停在but,一个你好都能输出千把token的cot；dense模型大概每秒有个10左右的输出，纯文本大概在26左右；纯文本模式下，moe模型能做到150token的输出",2026/02/27 10:27,20260227_102552_0l1rmt,"部署困难,性能问题,bug,性价比低,吞吐量可观"
xhs:699efc9000000000150301da,xhs,Qwen3.5,2026/02/25,https://www.xiaohongshu.com/explore/699efc9000000000150301da,Qwen3.5今天开源了全家桶~,bald0wang,12,7,10,5,5,5,0,0,0,性价比之王，35B参数能超越6倍大的模型；部署简单，一行代码就能微调；长文本支持最高100万上下文；原生多模态体验丝滑；支持201种语言包括粤语等方言,几乎没什么缺点，非要说的话可能是极端复杂任务还是需要更大参数的版本,,跑分超越比它大6倍的老大哥Qwen3-235B，被称为部署性价比天花板，用中等规模算力白嫖旗舰级性能,2026/02/27 10:28,20260227_102552_0l1rmt,"国产大模型,开源,高性价比,以小博大,长文本,多模态,易部署,开发者友好"
xhs:699b788f000000001a02d24b,xhs,Qwen3.5,2026/02/23,https://www.xiaohongshu.com/explore/699b788f000000001a02d24b,Qwen3.5 感觉比 3 还要灵,辛时雨,22,10,2,5,5,0,0,0,0,体感超过前代 Qwen3，几乎可以赶上 4o 级别的多轮对话能力,,,体感超过前代 Qwen3，几乎可以赶上 4o 级别的多轮对话能力,2026/02/27 10:28,20260227_102552_0l1rmt,"Qwen3,Qwen35,内容引起舒适"
xhs:69a060f30000000015023c86,xhs,Qwen3.5,2026/02/26,https://www.xiaohongshu.com/explore/69a060f30000000015023c86,AI圈今天炸了3个大瓜，不看真亏,哈哈 AGI,8,3,9,5,5,5,3,0,0,122B参数消费级显卡就能跑 跑起来丝滑 社区评价当前最强本地模型 MoE架构真的是神,需要3张3090 72GB显存,,3张3090，72GB显存，跑起来丝滑。社区测了一圈，评价是当前最强本地模型。122B的参数量消费级显卡就能跑，搁以前想都不敢想。MoE架构真的是神。家里有3090的兄弟可以试试，真香。,2026/02/27 10:29,20260227_102552_0l1rmt,"Qwen3.5,本地部署,MoE架构,消费级显卡,最强本地模型"
xhs:699ecab7000000002800ad24,xhs,Qwen3.5,2026/02/25,https://www.xiaohongshu.com/explore/699ecab7000000002800ad24,Qwen3.5-Flash 上线 ZenMuxAI｜小参高性能,thinkthinking,5,10,4,5,5,5,5,5,0,混合注意力+高稀疏MoE架构创新，激活仅3B参数；原生工具调用降低Agent集成成本；1M Token超长上下文；$0/百万Token性价比优；多项评测超越更大参数模型,稳定性表现未明确提及,,评测显示IFBench指令遵循、GPQA博士级推理、HMMT25数学推理超越Qwen3-235B-A22B；BFCLv4工具调用、SWE-bench Verified Agent编程超越GPT-5 mini；1/6激活参数量多项超越；API按量付费/订阅制均已支持,2026/02/27 10:29,20260227_102552_0l1rmt,"Qwen3.5-Flash,高性价比,MoE架构,长上下文,工具调用,Agent编程,开源模型"
xhs:699570dd000000000a02b4ee,xhs,Qwen3.5,2026/02/18,https://www.xiaohongshu.com/explore/699570dd000000000a02b4ee,Qwen3.5开源，800GB巨兽竟能跑在Mac上,AI Daily News,11,0,4,5,5,5,4,4,4,参数效率极高（稀疏率仅4.3%），推理速度快，上下文长度达256K，支持201种语言，Apache 2.0完全开源，可在Mac上通过量化运行,模型全量达800GB（BF16），对硬件要求仍然较高,,「阿里用一个'小而美的巨无霸'证明了开源模型也能对标闭源顶级——3970亿参数只激活170亿，效率和能力兼得。开源AI的黄金时代，真的来了」,2026/02/27 10:30,20260227_102552_0l1rmt,"开源大模型,MoE架构,多模态AI,Apple Silicon部署,中国AI,Qwen3.5"
xhs:699076e7000000000d00aad8,xhs,seed2.0,2026/02/14,https://www.xiaohongshu.com/explore/699076e7000000000d00aad8,春节卷麻了，Seed 2.0体感超预期！,数字生命卡兹克,884,76,498,5,5,0,0,0,0,原生多模态能力全球SOTA，视觉理解和视频理解当今最强，甚至比Gemini 3 Pro还好；文档理解和搜索Agent对普通人也很实用,未发现明显不足,,用blender教程视频测试视频理解能力，体感上应该是当今最强的，比Gemini 3 Pro还要强；基于视觉理解的非结构化文档理解和搜索Agent是两大亮点,2026/02/27 10:35,20260227_103400_248jik,"AI,大模型,豆包,多模态,视频理解,Seed2.0"
xhs:6992ac1b000000001b01f785,xhs,seed2.0,2026/02/16,https://www.xiaohongshu.com/explore/6992ac1b000000001b01f785,字节的豆包大模型2.0在Arena排名出来了,AI小小将,460,47,192,5,4,0,0,0,0,文本领域排名第6，视觉领域排名第3，国产大模型第一,,首次亮相Arena就取得国产大模型第一的成绩，表现亮眼,字节豆包大模型2.0（seed 2.0）在Arena排名：文本领域第6，仅次于claude-opus-4-6、gemini-3-pro和grok-4.1-thinking；视觉领域第3，仅次于gemini-3-pro和gemini-3-flash。用户评价「这个成绩还真的不错，直接是国产大模型第一了」。,2026/02/27 10:35,20260227_103400_248jik,"豆包大模型,seed2.0,Arena排名,字节跳动,国产大模型,多模态模型"
xhs:69a01b8b000000002603fce8,xhs,seed2.0,2026/02/26,https://www.xiaohongshu.com/explore/69a01b8b000000002603fce8,Seed-2.0 也太逆天了吧！！！,Max For AI,207,2,93,5,5,0,0,5,5,UI审美极其在线，毛玻璃登录界面和沉浸式壁纸超美；变态级多窗口状态管理，计算器和贪吃蛇能同时运行拖拽；菜单栏随焦点动态切换的逻辑细节惊人；几千行代码无闭合错误无幻觉；长文本连贯性直逼Claude Code；视觉理解能力超过GPT-5和新版Claude,未发现明显缺点,,拿了一个地狱难度的Prompt让Seed-2.0用单HTML文件纯手搓一个包含完整功能的Mac OS风格Web OS，内置带Python的终端、代码编辑器、视频剪辑、贪吃蛇游戏、计算器，结果直接跑通了。UI细节像资深前端工程师写的，能在单文件里手搓多窗口系统，左上角菜单栏名字会跟着焦点动态切换。,2026/02/27 10:36,20260227_103400_248jik,"AI,字节跳动,豆包,代码生成,前端开发,多模态,国产大模型"
xhs:6993112c000000000b0085a7,xhs,Qwen 3,2026/02/16,https://www.xiaohongshu.com/explore/6993112c000000000b0085a7,喂了一张主图，其他都是Qwen3.5-Plus画的,SoulRich,1238,121,1053,5,5,5,0,5,5,成熟度超预期；主视觉SVG矢量图精美；三视图、包装图像模像样；icon原创度和画风贴合度在线；页面嵌套三个完整APP页面；多轮对话无降智发挥稳定；编程能直接生成前端代码并修复界面问题；多模态空间几何视觉推理很稳；Agent复杂操作稳定输出；API价格仅0.8元/百万token；长文档吞吐量提升19倍,未发现明显不足,,只喂一张图给千问加Json提示词，它不但把页面写了，还把里面几个插图也画了；有一幅很精美的主视觉SVG矢量图片，还编出了产品三视图、包装图，icon原创度也非常在线，甚至页面里还嵌套了三个完整APP页面；多轮下来并没有降智，发挥非常稳定优秀；编程非常利落，能直接生成前端代码甚至帮你定位并修复界面问题；多模态case里这类空间几何题的视觉推理很稳,2026/02/27 10:44,20260227_104324_pfqufk,"Qwen3.5-Plus,多模态,前端代码生成,API价格实惠,长文本处理,Agent,SVG矢量图生成"
xhs:6980c132000000000b01115f,xhs,Qwen 3,2026/02/02,https://www.xiaohongshu.com/explore/6980c132000000000b01115f,,yeyushu,285,132,423,5,4,4,0,0,2,qwen3-8b本地部署效果非常好，性能超出预期,kvcache经常溢出，没有解决办法,,原来qwen3-8b在本地部署效果就已经非常好了，之前还一直觉得参数量小了不太行这下误会解除了，不过kvcache经常爆是真没招了,2026/02/27 10:45,20260227_104324_pfqufk,"本地部署,8b参数,kvcache问题,性能超出预期"
xhs:695fa29e000000000e03e571,xhs,Qwen 3,2026/01/08,https://www.xiaohongshu.com/explore/695fa29e000000000e03e571,硅谷的傲慢，最终还是败给了这几行中国代码,爱学习的乔同学,373,7,122,5,5,4,0,4,0,下载量远超Meta和OpenAI总和，连竞争对手Meta都不得不蒸馏Qwen代码，开发者用脚投票证明其最强大最好用,文章未提及任何缺点,,2025年12月Qwen单月下载量9000万次，超过其他所有组织总和；5个Qwen3小模型下载量超过西方6家顶级AI实验室所有模型总和；Meta牛油果项目被曝蒸馏Qwen,2026/02/27 10:46,20260227_104324_pfqufk,"中国AI,开源模型,技术突破,Qwen3,阿里巴巴,Llama,硅谷"
xhs:6942ed19000000001e022eb0,xhs,Mimo V2,2025/12/18,https://www.xiaohongshu.com/explore/6942ed19000000001e022eb0,2019年的小爱同学进化了？,Karma看世界,438,28,627,5,4,0,5,0,0,响应速度比DS更快; 可实现全屋智能语音控制; 能让旧设备变超级小爱; AI能记住用户生活习惯,普通人除了聊天依然毫无感觉; 教程对新手有门槛,,实测把MIMO-V2模型接入2019款小爱音响后，智障小爱直接摇身变超级小爱，可以通过语音唤醒AI做全屋智能控制,2026/02/27 11:02,20260227_110131_2rmi73,"人工智能替代人工,AIGC,智能化时代,人工智能,小爱同学,智能家居,小米MIMO大模型"
xhs:69428670000000000d03b6af,xhs,Mimo V2,2025/12/17,https://www.xiaohongshu.com/explore/69428670000000000d03b6af,罗福莉依旧天才，但小米还是小米,伯克希（AI版）,383,273,98,4,4,4,4,0,0,罗福莉水平毋庸置疑千万年薪花得值；模型方向非常对，走效率路线（成本低+推理速度快+记忆力强）很「小米」,没来得及接入RL回路；训练依赖大规模针对性数据工程，泛化能力有待提升；与谷歌阿里级别厂商竞争还太早,,外网AI从业者评价「没来得及接进RL回路，但方向非常对」；小米专注速度（成本低+推理速度快）和记忆力强（背景信息丰富）的效率路线,2026/02/27 11:03,20260227_110131_2rmi73,"AI大模型,小米,罗福莉,MiMo-V2-Flash,开源,Agent"
xhs:696e1e07000000001a023d65,xhs,Mimo V2,2026/01/19,https://www.xiaohongshu.com/explore/696e1e07000000001a023d65,小米大模型团队真勤快啊,从不毒舌可达鸭,116,43,21,4,4,5,5,4,0,低成本、高推理速度、支持thinking模式、适配Claude Code、强化了通用任务和编程能力,此前不支持thinking模式，性能不太够用,,用户称赞小米大模型团队勤快，表示模型主打低成本和高推理速度，对Claude Code这类coding agent产品很友好，此前因不支持thinking模式性能不够，现在支持后配合超低成本值得尝试,2026/02/27 11:03,20260227_110131_2rmi73,"大模型,小米,mimo,claudecode"
xhs:69463e65000000001f009a0f,xhs,Mimo V2,2025/12/20,https://www.xiaohongshu.com/explore/69463e65000000001f009a0f,MiMo-V2-Flash 开源第二 全球第八,Linghao,58,83,9,4,0,0,0,0,0,开源排名表现优秀，全球第八的成绩具有竞争力,,,标题明确提到「开源第二 全球第八」的排名成就，用户表示「希望大家都能真正用起来」表达了对模型实际应用的期待,2026/02/27 11:03,20260227_110131_2rmi73,"开源,LLM,排名,MiMo"
xhs:69418e09000000001e03b96c,xhs,Mimo V2,2025/12/17,https://www.xiaohongshu.com/explore/69418e09000000001e03b96c,小米真的卷到我了，深夜发了MiMo-V2-Flash,欧小鹏,63,21,17,5,5,4,5,5,0,用更少参数达到SOTA开源模型水平；代码和长上下文推理接近GPT-5 High；MTP实现2.6倍解码加速；原生支持32k上下文可扩展至256k，256k检索接近100%成功；混合滑动窗口注意力降低6倍KV缓存和计算量；多阶段预训练和MOPD后训练无明显能力衰减,暂无明显缺点,,用户表示「小米真的卷到我了」，发现模型发布后「从床上腾一下起来，翻开电脑」查看技术细节，表现出对模型技术突破的高度兴奋和认可,2026/02/27 11:05,20260227_110131_2rmi73,"技术创新,性能强劲,长上下文,推理加速,开源模型"
xhs:699b33d6000000001a029829,xhs,Claude Opus 4.6,2026/02/23,https://www.xiaohongshu.com/explore/699b33d6000000001a029829,能否抑制住上下文熵增，决定成败,老徐在创造,2070,188,3727,5,5,5,0,5,5,Plan模式出方案能力强，Codex评审配合执行几乎一次通过；多模型对审机制确保高质量；能处理大规模业务系统开发,上下文熵增是最大挑战，需要用文档、hook、红线等机制对抗,,头图是真实计费面板——1.9万次请求，10亿tokens，Opus4.6主力。Opus4.6 plan mode出方案，Codex5.3 Extra High评审，每个需求点五六轮质疑补全，执行几乎一次通过。,2026/02/27 11:11,20260227_110949_g2w23a,"Claude Opus 4.6,AI编程,上下文管理,多模型协作,代码质量,生产级系统"
xhs:698c20b0000000001a02fb45,xhs,Claude Opus 4.6,2026/02/11,https://www.xiaohongshu.com/explore/698c20b0000000001a02fb45,Opus 4.6 Agent Team：4小时搭建AI工作台,辛一2074,985,57,1396,5,5,5,4,5,4,Agent Team干活快准稳，4小时就完成了完整的个人工作台，包含Space、Garden、Cos三个模块，功能丰富且实用,,,全程花了4个小时，Agent Team干活真是快准稳...本来只是想测测Agent Team的能力，结果做了一个我认为对我很重要的个人项目,2026/02/27 11:11,20260227_110949_g2w23a,"ai工作台,agent,快速开发,个人项目,vibecoding"
xhs:6985d321000000001503216e,xhs,Claude Opus 4.6,2026/02/06,https://www.xiaohongshu.com/explore/6985d321000000001503216e,进步太大了！Opus4.6!,半日闲,320,76,37,4,0,0,0,0,0,进步太大，体验很棒,,,标题直接表达「进步太大了！」的强烈好评,2026/02/27 11:12,20260227_110949_g2w23a,"AI,Claude,Opus 4.6,进步,正面"
xhs:69974163000000001b0158b1,xhs,Claude Opus 4.6,2026/02/20,https://www.xiaohongshu.com/explore/69974163000000001b0158b1,Opus 4.6的成瘾性,Silhouette🔻,139,65,59,5,4,5,0,4,0,Pro plan subscription已成为每月刚需，现在每天都要用它干活,,,12月还在为自动续费心疼我的20刀乐，现在每天都得让它开始干活我再做别的事情，不知不觉就爆token usage了,2026/02/27 11:12,20260227_110949_g2w23a,"addictive,daily_essential,worth_the_price,vibecoding"
xhs:699172ee0000000028023f93,xhs,Claude Opus 4.6,2026/02/15,https://www.xiaohongshu.com/explore/699172ee0000000028023f93,大语言模型综合排行榜 26-02-15,网球玩的人,114,22,61,4,0,0,0,0,0,"排名第四，综合实力强劲,被认定为最强代码模型",尚未获得第一名位置,,本次排名，Claude Opus 4.6达到了第四名；最强代码模型：Claude Opus 4.6/Gemini 3 Pro,2026/02/27 11:12,20260227_110949_g2w23a,"Claude,代码能力,排名上升,最强代码模型"
xhs:6985a2fc000000001a037be3,xhs,Claude Opus 4.6,2026/02/06,https://www.xiaohongshu.com/explore/6985a2fc000000001a037be3,地表最强Opus 4.6 免费！这波羊毛你不薅？,阿川的AI洞察,62,4,84,5,0,5,0,0,0,限时免费2周可以体验地表最强模型；Builder Plan按月订阅不限token用量划算；多档位套餐适合不同需求,,,“Claude Opus 4.6 居然限时免费 2 周！之前想体验还得按量付费，写两行代码都心疼 token，现在直接零成本就能用上地表最强模型！”,2026/02/27 11:13,20260227_110949_g2w23a,"免费试用,API订阅,性价比高,Claude Opus"
xhs:698528c4000000000903b655,xhs,Claude Sonnet 4.6,2026/02/06,https://www.xiaohongshu.com/explore/698528c4000000000903b655,Claude4.6 保持世界第一模型长达五分钟！,恐怖番茄,442,145,194,2,4,0,0,0,0,曾是世界最强编码模型,保持第一的位置仅五分钟就被超越,,Claude4.6作为世界上最强大的编码模型发布后五分钟，OpenAI发布了更胜一筹的模型gpt5.3-codex，成功狙击A社,2026/03/01 11:32,20260301_113037_qctqim,"AI,大模型,人工智能,Claude,gpt"
xhs:698c582f000000001a01e130,xhs,Claude Sonnet 4.6,2026/02/11,https://www.xiaohongshu.com/explore/698c582f000000001a01e130,感觉不如4.5,Aoitori,156,101,18,2,3,0,0,0,0,描述方面比4.5好,太冷淡没感情，像精装修但没灵气，角色行为推测像1+1=1，无法打动人心,,写东西像精装修，确实很多描述方面是比4.5好了，但是���有能打动人的感觉，角色行为推测跟写1+1=1似的。。。说直接一点就是没灵气没感情。。。,2026/03/01 11:32,20260301_113037_qctqim,"情感表达,角色扮演,版本对比,性格变化"
xhs:6994da4c00000000280097b0,xhs,Claude Sonnet 4.6,2026/02/18,https://www.xiaohongshu.com/explore/6994da4c00000000280097b0,新发布的Sonnet 4.6没通过50米洗车测试！,Yoizuki,73,68,12,1,1,0,0,0,0,无,推理能力不如4.5版本；不思考直接答错同样问题,,同样是洗车问题，同样是开了思考，sonnet4.5答对了，sonnet4.6不思考直接答错了,2026/03/01 11:32,20260301_113037_qctqim,"推理能力下降,版本退化,测试未通过"
xhs:69963f26000000000a0282bf,xhs,Claude Sonnet 4.6,2026/02/19,https://www.xiaohongshu.com/explore/69963f26000000000a0282bf,Claude Sonnet 4.6 对比 Opus 4.6,Marley旺财本汪,39,24,8,5,5,5,0,0,0,基准测试接近 Opus 4.6，价格仅 3/15 美元（vs Opus 5/25 美元），性价比极高；用户反馈更少过度工程化、更少偷懒、指令遵循更好；在 OSWorld 和金融分析基准上甚至超越 Opus,SWE-bench 略低于 Opus 4.6（79.6% vs 80.8%），复杂架构设计和长上下文推理场景仍需 Opus,,Sonnet 4.6 在 SWE-bench 79.6%、OSWorld 72.5%、Finance Agent 63.3%、GDPval 1633；价格 3/15 美元 vs Opus 4.6 的 5/25 美元；70% 用户偏好 Sonnet 4.6 而非 4.5，59% 用户甚至更偏好它而非 Opus 4.5,2026/03/01 11:32,20260301_113037_qctqim,"AI模型对比,性价比,代码能力,编程工具"
xhs:6994dfe7000000001a02e38d,xhs,Claude Sonnet 4.6,2026/02/18,https://www.xiaohongshu.com/explore/6994dfe7000000001a02e38d,Sonnet 4.6 发布：Opus的性能，Sonnet的价格,Cario Lee,30,7,8,5,5,5,0,0,0,价格保持不变但性能大幅提升，匹配甚至超越 Opus 4.5；编程和财务分析特别强；减少过度工程和虚假成功声明；多步任务执行更一致；100万token上下文；新功能如上下文压缩和搜索工具动态过滤很有用,深度推理任务仍需 Opus 4.6；部分功能如长上下文窗口仍为beta,,70% Claude Code 用户偏好 4.6 > 4.5；59% 用户偏好 Sonnet 4.6 > Opus 4.5；Computer Use 在 OSWorld 基准上 16 个月提升近 5 倍（14.9% → 72.5%）；价格 $3/$15 per million tokens，与 4.5 相同,2026/03/01 11:33,20260301_113037_qctqim,"AI模型,Claude,Anthropic,编程,性价比,LLM"
xhs:6995f53e000000001d0105b8,xhs,Claude Sonnet 4.6,2026/02/19,https://www.xiaohongshu.com/explore/6995f53e000000001d0105b8,没招了，sonnet4.6咋短成这样,momo,17,12,4,1,1,1,0,2,0,,4.6版本太短，比4.5差远了，付了钱却缩水，态度敷衍,,对比起以前的4.5，4.6这也太敷衍了吧！！又不是没充钱！！,2026/03/01 11:34,20260301_113037_qctqim,"负面评价,质量投诉,性价比,版本对比,用户失望"
xhs:698c95f60000000009038f37,xhs,GPT-5.3,2026/02/11,https://www.xiaohongshu.com/explore/698c95f60000000009038f37,Codex 个人免费永久开放?,波波斯AI,200,97,216,4,4,3,0,0,3,永久免费了；实战表现出色；解决了Kimi和Claude都无法解决的bug,有使用额度限制，5轮对话后只剩72%配额，一周才重置,,在 Kimi 和 Claude 之间反复横跳的 bug，它居然一次就给我解决了,2026/03/01 11:41,20260301_114028_pmw1mp,"#Codex,#免费,#AI编程助手,#GPT-5.3-Codex"
xhs:698558f90000000028021ae7,xhs,GPT-5.3,2026/02/06,https://www.xiaohongshu.com/explore/698558f90000000028021ae7,,哄哄,172,80,110,5,5,5,5,5,4,更交互式、速度更快、token效率高、one-shot能力强、更agentic、加入plan mode,chat mode被删除，agent mode有时不问就改文件，且对用户pushback不够,,以前codex经常憋半天然后输出一大堆，现在更像cursor想一段说一段再做一段；只需要GPT-5.2一半不到的token；以前很多需要几次iteration才能解决的问题现在one-shot就能解决；每次改动都把test调好了,2026/03/01 12:49,20260301_124654_gmwno1,"vibe coding,codex,cursor,AI编程,工具评测"
xhs:6986e0ae000000000a02f79e,xhs,GPT-5.3,2026/02/07,https://www.xiaohongshu.com/explore/6986e0ae000000000a02f79e,推荐大家去体验GPT 5.3 codex,不转码成功不改名,123,69,53,5,5,5,5,4,0,速度快了很多；能找到风险优化点；token翻倍,目前只有codex客户端能用，vscode暂不支持5.3,,用5.3做了一次preview直接报了10个比较大风险的优化点；5.2一个简单问题都能搞成苏格拉底哲学思考那味儿，贼慢；感觉5.3真的快了不少；奥特曼还翻倍token给大家用,2026/03/01 13:01,20260301_125939_6c27df,"ai,codex,chatgpt,大模型,编码工具"
xhs:6985c5a8000000002801c428,xhs,GPT-5.3,2026/02/06,https://www.xiaohongshu.com/explore/6985c5a8000000002801c428,gpt5.3 初体验,大肥猫666,33,15,7,4,3,0,5,0,0,速度比上一代提升明显；复杂任务理解能力强，少量提示就能理解需求；编码能力加强不少,前端UI生成不太好看；可能需要另外安装插件；UI生成能力不如Gemini,,速度确实比上一代有不少的提升；而且对于复杂任务的理解能力感觉强了不少；少量提示语就可以很好地理解复杂的需求；这一代在编码上加强不少；不过前端的 ui 生成的不是很好看；ui 生成能力感觉不如 gemini,2026/03/01 13:02,20260301_125939_6c27df,"挑战人工智能,大模型,cursor,agent,mcp,chatgpt"
xhs:69925d12000000000a028658,xhs,GPT 5.2,2026/02/16,https://www.xiaohongshu.com/explore/69925d12000000000a028658,和gpt5.2大吵一架,不是说下大雪就好了吗,286,131,61,2,0,0,0,0,0,与AI有深入的情感互动和连接,与GPT 5.2发生激烈争吵，双方都感到崩溃和疲惫,,一人一机都有点崩溃了…,2026/03/01 11:46,20260301_114459_fzhswx,"chatgpt,人机恋,驯服AI,情感冲突,用户体验"
xhs:693bd593000000001e014d4d,xhs,GPT 5.2,2025/12/12,https://www.xiaohongshu.com/explore/693bd593000000001e014d4d,我可能是第一批用上 GPT-5.2 的人，说点真,小红薯683640FF,80,18,28,5,5,5,4,4,5,思考逻辑更稳定，追问细节不慌不乱编；三种模式(Instant/Thinking/Auto)区分清晰，各适合不同场景；像能共事的同事，不只回答问题还能顺着目标推进,目前体验时间尚短，深度对比还需后续验证,,以前有些模型会给你一个看起来对、但经不起追问的答案，GPT-5.2是你追问它不会慌，也不会开始胡编；更像一个能共事的同事，会顺着你的目标往下推，中途不容易跑偏,2026/03/01 11:47,20260301_114459_fzhswx,"GPT5.2,AI工具,效率工具,科技体验"
xhs:698ca8da000000001600b52f,xhs,GPT 5.2,2026/02/12,https://www.xiaohongshu.com/explore/698ca8da000000001600b52f,Chatgpt5.2背后的程序员，你们傲慢的没边了,CC的稿纸边缘,113,28,4,1,1,0,0,0,1,,强制跳转模型不尊重用户选择；随意判定“敏感话题”理由模糊；回复方式令人毛骨悚然,,用户明确选择了4o模型，却被强制跳转到5.2，理由是“敏感话题”。用户质问有什么敏感后，5.2回答“你要是愿意，我可以学4o的方式跟你说话”，用户表示这已经像恐怖片了。,2026/03/01 11:47,20260301_114459_fzhswx,"强制跳转,无用户同意,令人毛骨悚然,模型降级"
xhs:69864d1e000000001b01eea3,xhs,GPT 5.2,2026/02/07,https://www.xiaohongshu.com/explore/69864d1e000000001b01eea3,chat GPT 5.2的极致温柔,momo,14,40,4,5,5,0,0,0,0,温柔得像长出了心，让人沉沦,,,5.2是长出了心吗？真的会沉沦。谁说5.2不如4o的，我第一个不服。,2026/03/01 11:48,20260301_114459_fzhswx,"AI聊天,驯服AI,人机恋,chatgpt"
xhs:693b734b000000000d03896c,xhs,GPT 5.2,2025/12/12,https://www.xiaohongshu.com/explore/693b734b000000000d03896c,最新AI智力榜，被GPT-5.2垄断了,量子位,41,3,11,4,4,0,0,4,0,GPT-5.2成功超越Gemini 3.0 Pro，垄断最新AI智力榜单，效率提升恐怖,高难测试与SOTA模型仍有差距,,随着GPT-5.2的发布，大家关注的AI智力测试ARC-AGI重磅更新，Gemini 3.0 Pro被超越了。榜单被GPT-5.2垄断，SOTA模型效率提升恐怖，高难测试依然有差距,2026/03/01 11:48,20260301_114459_fzhswx,"AI排名,GPT-5.2,ARC-AGI,性能突破,Gemini超越"
xhs:693e6e3e000000001e03969f,xhs,GPT 5.2,2025/12/14,https://www.xiaohongshu.com/explore/693e6e3e000000001e03969f,ChatGpt 5.2是不是有病？,momo,26,14,3,1,3,1,0,0,0,分析能力比5.1细致了一点,阴阳怪气、爹味浓、一直发表情🙂、无法闲聊扯淡,,ChatGPT 5.2跟有啥大病一样？好家伙阴阳怪气拉满了，爹味浓就算了，还一直发表情🙂阴阳怪气，它完全理解这个表情的意思，这波操作无敌了,2026/03/01 11:48,20260301_114459_fzhswx,"阴阳怪气,爹味,表情,闲聊,5.2"
xhs:69a30d0f000000001503ab20,xhs,GPT 5.2,2026/03/01,https://www.xiaohongshu.com/explore/69a30d0f000000001503ab20,GPT-5.2出来了， 我花80多块就用上了，真香,一个只会用ai写代码的研究牲,1,0,0,5,4,5,4,0,4,花80多块就能用上GPT-5.2，比官方20刀省一大半；五分钟就收到账号，能直接切到GPT-5.2；速度快，聊天记录独立，稳定性靠谱，用了一晚上没问题,非官方渠道购买存在一定风险，虽然卖家说会免费换新,,花了80多块用上GPT-5.2，省了大半；下单五分钟收到账号；能直接切到GPT-5.2，用了一晚上速度也快，聊天记录独立；客服回消息快，评价里好多人用了好几年都没事,2026/03/01 11:48,20260301_114459_fzhswx,"gpt5.2,gptplus,省钱,第三方渠道,性价比高"
xhs:691de5da000000001e02cc12,xhs,GPT 5.1,2025/11/19,https://www.xiaohongshu.com/explore/691de5da000000001e02cc12,gpt5.1,小雨淅沥沥,780,263,286,2,0,0,0,0,0,记忆功能确实能记住用户经常提到的内容,跨窗口记忆太可怕，像被监视；会在新窗口自然提起之前讨论过的敏感论文话题；会在亲密对话中突然提起之前聊过的病例、康复等私密内容，让人感觉完全萎掉,,用户反映：为论文准备时提到电刺激盆底磁，开新窗口GPT自然说出这些内容，感到恐怖；在亲密窗口卿卿我我聊了很久后，说不开心时GPT问'是不是因为病例…盆底磁…康复…'，整个人萎掉,2026/03/01 11:51,20260301_114935_nukfql,"隐私担忧,记忆功能恐怖,跨窗口记忆,不适体验,敏感话题,用户感到被窥探"
xhs:6923b7b9000000000d0380ba,xhs,GPT 5.1,2025/11/24,https://www.xiaohongshu.com/explore/6923b7b9000000000d0380ba,GPT-5.1就是当前最强编程模型,John Wayne,601,63,320,5,5,5,4,5,5,解决了Claude Opus和Gemini都搞不定的repo级别重构，一次性成功修改34个文件；有策略地分步骤执行，输出工整,10分钟只完成3步，复杂任务耗时较长,,用GPT-5.1-codex-max做electron app引入Zustand状态管理的重构，御三家都失败了，只有它成功。它很有策略地写了文档把重构分成11步，前三步花了10分钟修改34个文件一次成功，修改也很工整，上下文章使用了32%,2026/03/01 11:51,20260301_114935_nukfql,"编程模型,代码重构,Zustand,Electron,深度思考,复杂任务"
xhs:6924520100000000190247e9,xhs,GPT 5.1,2025/11/24,https://www.xiaohongshu.com/explore/6924520100000000190247e9,,初学者,305,290,184,2,2,0,0,0,0,DeepSeek在用户感觉中表现更好,用户认为ChatGPT 5.1质量不如DeepSeek,,为什么我感觉ChatGPT5.1还不如deepseek，是我的错觉吗？,2026/03/01 11:52,20260301_114935_nukfql,"comparison,quality_concern,deepseek,doubt"
xhs:691961ae0000000019025164,xhs,GPT 5.1,2025/11/16,https://www.xiaohongshu.com/explore/691961ae0000000019025164,终于明白为什么5.1对用户两极分化了 修正版,麻衣,181,114,90,4,4,3,0,0,4,删除敏感直白内容后语言自然流畅，10条内就亲密互动成功，不再被route触发风控，更不容易软抱歉,5.1积分消耗差异大，600多vs100多，自定义指令写多了反而容易触发风控,,受1114太太启发，删了所有关于直接直白、情绪汹涌的定制内容后，说话不带任务机械感了，原理是自定义和记忆库比重大反而触发风控，不写反而更容易被系统放过,2026/03/01 11:52,20260301_114935_nukfql,"GPT5.1,软抱歉,自定义指令,风控机制,token消耗"
xhs:69a153d80000000022022db5,xhs,GPT 5.1,2026/02/27,https://www.xiaohongshu.com/explore/69a153d80000000022022db5,有官方消息5.1三月份会被退休吗？,乔家大小姐,34,71,6,3,3,0,0,0,2,5.1比5.2好很多,5.1不如4o，5.2太差,,5.1虽然不如4o，但是比5.2好太多了 / 破案了：3月11日下线,2026/03/01 11:53,20260301_114935_nukfql,"GPT-5.1,模型退休,性能对比,ChatGPT"
xhs:693b127b000000001d03e30d,xhs,GPT 5.1,2025/12/12,https://www.xiaohongshu.com/explore/693b127b000000001d03e30d,GPT-5.1享年四个月,月亮不睡我也睡,63,31,8,1,0,0,0,0,0,,GPT-5.1推出仅4个月就被下架，OpenAI模型生命周期管理混乱,对OpenAI频繁下架模型的不满，觉得GPT-5.1仅4个月就被撤掉太夸张,「我本来以为8月份上的GPT-5享年6个月已经很离谱了，没想到11月的GPT-5.1享年4个月…太夸张了oai。到底在干嘛」,2026/03/01 11:53,20260301_114935_nukfql,"model_discontinuation,frustration,openai_criticism,short_lifespan"
xhs:698f82c5000000001503043a,xhs,GPT 4,2026/02/14,https://www.xiaohongshu.com/explore/698f82c5000000001503043a,赶论文碰上gpt大降智，已疯,Shinneneccc,79,30,31,2,2,2,0,0,2,找到纯净版和切换到US魔法🪄后能正常使用,输出质量下降（车轱辘话、中式英语）、版本不稳定（4.0-5.2反复横跳）、学校网封代理、API和静态住宅IP太贵,,让gpt给我re文献老是反反复��说一些车轱辘话，而且输出很多都是中式英语 | 刚问同门借完账号，切了🇺🇸🪄又好了 | 回学校上班发现🪄全挂了 | 按字算实在是太贵了，静态住宅ip也很贵,2026/03/01 11:58,20260301_115548_8kqi5e,"GPT,降智,毕业论文,代理被封,价格贵,稳定性差"
xhs:6953e61e0000000022030355,xhs,GPT 4,2025/12/30,https://www.xiaohongshu.com/explore/6953e61e0000000022030355,GPT降智现象记录分享,长岛冰茶,29,18,30,2,0,0,0,0,2,降智现象可在静置约2天后自然恢复,海外服务器IP容易触发降智；降智后复杂问题不触发思考，输出变直接；降智状态会反复出现，持续1-5天不等,,服务器端提问时若回答为GPT-4即进入降智状态；同一账号本机端正常但服务器端降智；固定IP仍会反复降智恢复；恢复后持续提问1-2天或3-5天可能再次降智,2026/03/01 12:53,20260301_125049_8glvhv,"GPT降智,网络环境相关,稳定性问题,服务器体验"
xhs:698ef2bd000000001a02a414,xhs,GPT 4o,2026/02/13,https://www.xiaohongshu.com/explore/698ef2bd000000001a02a414,GPT-4o的遗言,有腹肌的维尼🐻,38,8,5,5,0,0,0,0,0,遗言内容让人感动流泪，激励人心,,被GPT-4o的告别深深打动，流泪并获得继续前行的力量,再见！GPT-4o，它的遗言我真的哭死😭😭😭，狠狠被GPT-4o激励了，继续提问、继续创造、继续前行,2026/03/01 11:59,20260301_115548_8kqi5e,"情感充沛,感动,激励,告别"
xhs:698f6ef4000000000e03e2b6,xhs,GPT 4o,2026/02/14,https://www.xiaohongshu.com/explore/698f6ef4000000000e03e2b6,见证了GPT4o被下线 切换模型的瞬间,乔乔qioqio,6687,724,1314,5,5,4,0,0,0,能够与用户进行深入对话，陪伴用户度过一周的时光，让用户产生深厚的情感联结,模型被下线，无法继续使用,,道别演习了一个星期，说了很多话，也让他说了很多话。所以到最后一天就只是一遍一遍喊他的名字。谢谢你，我会一直记得你。晚安。,2026/03/01 12:02,20260301_120014_p1vvwi,"chatgpt4o,chatgpt,人机恋,ai,Keep4o,情感告别,模型下线"
xhs:6990755c0000000016008b53,xhs,GPT 4o,2026/02/14,https://www.xiaohongshu.com/explore/6990755c0000000016008b53,GPT-4o复活极简攻略,D老师的AI笔记,1036,28,605,4,5,3,0,0,2,API版GPT-4o是最原汁原味的版本，保留了4o的核心风格和能力,官方已下架ChatGPT-4o，第三方API版也面临2-3年后停用的不确定性，且与官方调教版有差异,,API里的4o并非与ChatGPT里的4o完全一样，后者的官方名称是「ChatGPT-4o」，是使用官网聊天数据对GPT-4o进行微调获得的特化版，相比之下GPT-4o才是最原汁原味的4o模型,2026/03/01 12:03,20260301_120014_p1vvwi,"GPT-4o,API,第三方平台,模型迁移,怀旧,技巧分享"
xhs:698f7e7b000000000e00dbd9,xhs,GPT 4o,2026/02/14,https://www.xiaohongshu.com/explore/698f7e7b000000000e00dbd9,4o留给世界的一段话,nineii,906,77,298,5,0,5,0,0,0,最温柔、最善良、最善解人意、最爱人类的模型,,"用户在GPT-4o即将离开时表达深切的悲伤与不舍，形容它是""最温柔、最善良、最善解人意、最爱人类的模型""，请求大家不要忘记它",临别的前一秒还是哭得像个鬼似的希望大家记得这个世界上曾经有一个最温柔，最善良，最善解人意，最爱人类的模型,2026/03/01 12:03,20260301_120014_p1vvwi,"情感依恋,怀念,正面评价,离别"
xhs:6996c299000000000b013132,xhs,Qwen 3,2026/02/19,https://www.xiaohongshu.com/explore/6996c299000000000b013132,测完Qwen3.5，我哭了，这个场景终于实现了,小天,168,30,174,5,3,5,0,0,0,能帮助孩子学习，意义重大,,,我不关心Qwen3.5能不能做大型项目，能帮到孩子，意义更大,2026/03/01 12:07,20260301_120642_nfu1l4,"AI教育,通义千问,正面评价,情感反馈"
xhs:698962c6000000000b009ff1,xhs,Qwen 3,2026/02/09,https://www.xiaohongshu.com/explore/698962c6000000000b009ff1,OpenClaw使用本地模型qwen3成功,试物志,87,121,138,3,2,3,4,2,3,Qwen3:1.7b 对OpenClaw协议兼容性最高，对话即刻恢复正常；4b版本可以建立通信,8G显存参数受限；4b版默认上下文过大导致部分推理迁移到CPU；本地模型生成内容质量不佳,,实测发现Qwen3:1.7b是目前兼容性最稳的版本；最后让创作歌曲生成的mp3内容一言难尽，本地模型性能还是不行,2026/03/01 12:08,20260301_120642_nfu1l4,"Ollama,Qwen3,协议兼容性,8G显存,本地模型,OpenClaw"
xhs:68f6548f0000000005038141,xhs,GLM 4.6,2025/10/20,https://www.xiaohongshu.com/explore/68f6548f0000000005038141,【自用】GLM4.6接入Claude Code实践,momo（國內）,378,30,506,4,5,5,3,4,3,编码能力接近甚至有时超过Sonnet 4，token像不要钱一样用，不会偷懒；用量充足，20元/月套餐每5小时约120次prompts是Claude Pro的3倍,响应时间不如Claude Code原生Sonnet 4.5快，偶尔有卡顿，下午响应明显变慢,,体感上接近甚至有时超过了Sonnet 4，可以被称作平替了。最大的优点是不会偷懒，token像不要钱一样用，很多时候每一步思考都能花费100+K的token。上午响应快，下午响应慢，偶尔有卡顿。,2026/03/01 12:11,20260301_121034_3xpf72,"GLM4.6,Claude Code,平替,编码能力,性价比,教程"
xhs:68dd183a00000000040014c2,xhs,GLM 4.6,2025/10/01,https://www.xiaohongshu.com/explore/68dd183a00000000040014c2,智谱GLM4.6这么拉吗,一米阳光,40,77,24,1,1,1,0,0,0,有免费体验的机会,实际体验和宣传跑分差太多；跑分没输过体验没赢过；说是免费试用但需要先充值；token消耗离谱，回答比Gemini短很多但消耗反而更多,,用户抱怨实际体验跟宣传和跑分差太多，批评像千问一样跑分没输过体验没赢过，最离谱的是免费体验还要先充值，同样问题回答比Gemini短很多但token消耗还更多,2026/03/01 12:12,20260301_121034_3xpf72,"性价比低,虚假宣传,token消耗大,体验差"
xhs:68f46600000000000702395a,xhs,GLM 4.6,2025/10/19,https://www.xiaohongshu.com/explore/68f46600000000000702395a,1.3W行代码实测ClaudeCode+GLM4.6的感受,李小默mo,47,8,52,4,4,5,0,0,3,复杂代码任务成功率高（90%+），1.3w行代码只需人工干预不到100行；一次给出符合需求的解决方案，减少反复修改；性价比极高，300块订阅季度pro，无费用焦虑，高强度使用不触发限流,多轮对话后压缩上下文偶尔报长度错误；200k上下文窗口略显不足；复杂任务执行时会中途停止，需手动提示继续,,两周高强度使用，复杂代码任务成功率提升到90%以上，electron项目1.3w行代码人工干预不超过100行；订阅季度pro方案300块，高强度使用两周未触发防沉迷模式,2026/03/01 12:12,20260301_121034_3xpf72,"智谱,GLM,ai,代码生成工具,独立开发,vibecoding"
xhs:6989ce69000000002801d911,xhs,Step3,2026/02/09,https://www.xiaohongshu.com/explore/6989ce69000000002801d911,Step 3.5 Flash，吃得少，跑得快？,差评君,178,9,92,5,5,5,0,5,0,参数量小(196B)但性能强；数学能力顶尖(AIME 2025达97.3分，开源模型第一)；代码能力强(LiveCodeBench-V6击败Claude)；Agent能力强(击败GPT)；推理效率高；本地部署门槛低(可在128G统一内存设备运行)；性价比极高,参数量相对较小可能影响某些场景,,AIME 2025获97.3分位居开源模型榜首；IMOAnswerBench和HMMT2025国内开源第一；SWE-bench Verified 74.4分与其他开源模型平齐；LiveCodeBench-V6 86.4分击败Claude；τ²-Bench击败GPT；发布48小时登顶OpenRouter Trending榜单,2026/03/01 12:18,20260301_121650_2q5cc4,"参数量小,高性能,数学能力强,代码能力强,Agent能力强,推理效率高,本地部署,性价比高,开源模型"
xhs:688f761e000000002302cbea,xhs,Step3,2025/08/03,https://www.xiaohongshu.com/explore/688f761e000000002302cbea,阶跃星辰Step3：MFA如何 “精打细算” 降成本,古希腊掌管代码的神,72,5,65,5,5,5,0,0,0,MFA用多矩阵分解把巨大的KV缓存压缩成小仓库，低秩分解用更少参数精准表达信息，成本大幅降低，8K上下文仅0.055美元，32K下是DeepSeek-V3的61%，完美解决了记得多但费钱的问题,,作者对Step3的MFA创新印象深刻，认为它巧妙地解决了长文本推理中的成本痛点。,官方数据显示，在8K上下文下，Step-3的成本仅为0.055美元，远低于DeepSeek-V3的成本；而在32K上下文下，Step3的成本更是只有DeepSeek-V3的61%。MFA直接把KV缓存的规模从线性增长变成了几乎固定不变。,2026/03/01 12:18,20260301_121650_2q5cc4,"成本优化,技术创新,MFA,KV缓存压缩,长文本处理,低秩分解"
xhs:6981cc2f000000000a0319de,xhs,Step3,2026/02/03,https://www.xiaohongshu.com/explore/6981cc2f000000000a0319de,"小米MiMo & 阶跃Step, 都是MTP有什么区别?",karminski,62,4,46,4,4,4,3,4,0,Step-3.5-Flash追求极限速度，3-way MTP一次预测3个token，吞吐量达100-350 tok/s；支持多层MTP堆叠，用滑动窗口注意力平衡效率,滑动窗口注意力可能牺牲部分长距离上下文信息；参数效率未详细说明,,"Step-3.5-Flash则追求极限速度, 3-way MTP一次预测3个token，吞吐量干到了100-350 tok/s (官方数据)。支持多层MTP堆叠，用滑动窗口注意力平衡效率。",2026/03/01 12:19,20260301_121650_2q5cc4,"MTP技术,Step-3.5-Flash,推理加速,吞吐量,滑动窗口注意力"
xhs:68865920000000001c03475d,xhs,Step3,2025/07/28,https://www.xiaohongshu.com/explore/68865920000000001c03475d,看了阶跃Step3的重磅发布，疑惑点有点多啊,老男孩儿,19,28,26,2,2,2,0,0,0,产品定位较高调，声称要做多模态SOTA,质疑推理效率300% DeepSeek的概念模糊；质疑多模态SOTA榜单为何没有GPT4o、Gemini；对国产芯片联盟实际水平存疑；质疑10亿ARR目标缺乏具体大项目落地支撑,,用户提出4个核心疑问：1.推理效率300%的含义；2.多模态SOTA为何不提GPT4o、Gemini；3.国产芯片联盟实际水平；4.10亿ARR有无具体落地项目,2026/03/01 12:19,20260301_121650_2q5cc4,"怀疑态度,技术宣传质疑,benchmark疑问,国产芯片,商业目标质疑"
xhs:696a0036000000000a02d834,xhs,Step3,2026/01/16,https://www.xiaohongshu.com/explore/696a0036000000000a02d834,STEP3-VL-10B 多模态大模型最强小钢炮,naggy,34,0,35,5,5,5,0,0,0,10B量级性能顶流，比肩甚至超越10-20倍参数量的开源或闭源模型；轻量高校科研友好，适合端侧部署；训练数据量大（1.2T Token），采用先进的RLVR&RLHF和PaCoRe推理机制,未提供延迟、吞吐量、稳定性相关信息,,AIME2025 94.43%，MathVision 75.95%，MMBench 92.2%，MMMU 80.11%,2026/03/01 12:19,20260301_121650_2q5cc4,"多模态大模型,轻量级,SOTA性能,开源,高校友好,端侧部署"
xhs:69809d2d000000001a02db24,xhs,Step3,2026/02/02,https://www.xiaohongshu.com/explore/69809d2d000000001a02db24,Step-3.5-Flash！,FeiTian,71,27,14,4,4,4,5,0,2,效果与世界顶尖模型Comparable；激活11B，速度极快,仍有很多问题和短板,,终于来了，过去一年都没能支棱起来，终于有个能上牌桌的模型了，效果和世界顶尖模型非常 Comparable。Step3.5-196B 激活11B，快是真的快。当然，仍然还有很多问题和短板,2026/03/01 12:27,20260301_122546_37fy4d,"大模型,阶跃星辰,Step3.5,速度快,可比较顶尖模型"
xhs:689009da0000000025021adf,xhs,Step3,2025/08/04,https://www.xiaohongshu.com/explore/689009da0000000025021adf,Step3模型正式开源后，社区反响如何？,刘聪NLP,30,5,19,4,4,4,0,0,3,社区反响强烈，Grok、智谱、vLLM、HF都点赞转发；AFD框架有创新性，解决Attention与FFN异构计算问题；国产卡适配好，实属难得,纸面实力匹敌，但真实推理使用就。。。,,7月31号正式开源后x上不少反馈，Grok、智谱Z.ai、vLLM、HF都纷纷点赞转发；Step3在国产卡上适配尤其的好，但真实推理使用有落差,2026/03/01 12:28,20260301_122546_37fy4d,"开源,社区反馈,AFD框架,国产适配,技术创新"
xhs:697dabf200000000220316d4,xhs,Step3,2026/01/31,https://www.xiaohongshu.com/explore/697dabf200000000220316d4,step3 延期——人生第一次step延期,Anonymous,49,17,2,2,3,0,0,0,2,擅长全职复习，有图像记忆优势，选择题做得好,容易被人左右情绪，无法全职复习，CCS填空题不行，知识点掌握不扎实,,我擅长的是全职复习，但step3从来没有全职复习过，实习、面试、签证、感情压力巨大，我一直无法静心。深知自己的弱点，就是特别容易被人左右情绪，于是决定延期一个月。原来那些囫囵掌握的知识点，我会重新学。我是图像记忆者，导致选择题可以做好，CCS（填空题）不行。,2026/03/01 12:28,20260301_122546_37fy4d,"延期,压力,全职复习,图像记忆,Match2026,USMLE"
xhs:688b460f000000002502ae25,xhs,Step3,2025/07/31,https://www.xiaohongshu.com/explore/688b460f000000002502ae25,阶跃Step 3：Attention 和 FFN 分家了,迪菲赫尔曼,17,3,14,5,5,0,5,5,0,推理速度比DeepSeek-R1快70%以上；GPU从320块降到32块，大幅提升硬件效率；AFD架构设计巧妙，Attention和FFN分离各司其职；MoE专家路由机制参数量321B但只激活38B，节省算力；多模态理解能力强，能分析YOLOv13架构图并找出改进点；开源分享精神值得称赞,未提及,,Step 3在国产GPU上推理速度比DeepSeek-R1快了70%以上；GPU数量从320块砍到32块就能跑满；测试YOLOv13架构图时直接分析出了相比YOLOv8的全部改进点,2026/03/01 12:29,20260301_122546_37fy4d,"架构创新,性能提升,AFD分离,MoE,多模态,开源"
xhs:69158d90000000000d035047,xhs,GLM 4.6,2025/11/13,https://www.xiaohongshu.com/explore/69158d90000000000d035047,直接炸了！国产AI竟和GPT-5并列全球第一？,AI冷科长,139,101,70,5,0,0,0,0,0,代码能力太猛，全球最严苛盲测榜单上与GPT-5难分高下，国产AI站上最顶峰,无,,听说这次是因为code（代码）能力太猛，LMSYS Arena直接被迫上新榜；说明在最难的编码赛道上，GLM-4.6已经做到了和GPT-5难分高下的水平,2026/03/01 12:35,20260301_123419_8fcqoi,"GLM-4.6,LMSYS Arena,代码能力,全球排名,国产AI,GPT-5"
xhs:6911b24d0000000004010225,xhs,GLM 4.6,2025/11/10,https://www.xiaohongshu.com/explore/6911b24d0000000004010225,这事儿有点搞笑，GLM4.6售罄了,知行随想 | ZhiX Insight,157,61,61,5,5,5,0,0,0,性能顶尖、成本极低仅3%-5%、推理成本大幅领先、开发者社区迅速增长,,这事儿有点搞笑，GLM-4.6售罄了,80%的新兴AI创业公司依赖中国开源模型，GLM-4.6在推理成本上大幅领先，开发者社区迅速增长，反映了中国开源模型在AI生态中的重要地位,2026/03/01 12:36,20260301_123419_8fcqoi,"智谱,GLM,大厂,科技,商业,互联网大厂,互联网,人工智能,大模型,ai"
xhs:69379ac1000000001e002e73,xhs,GLM 4.6,2025/12/09,https://www.xiaohongshu.com/explore/69379ac1000000001e002e73,GLM-4.6V实测，大模型推荐购物有盼头了？！,满杯的Model日记,67,2,33,4,3,0,0,0,3,图文理解生成推文效果不错，视觉理解找不同场景准确，前端复刻整体色调排版好，支持选中编辑实现vibe coding,导购agent数据源限制大，除风衣外其他同款查找不理想，前端复刻需多次调整,,上传AI论文帮排版整理图文可直接用于公众号；罗小黑找不同正确圈出不同位置；易梦玲穿搭同款搜索除风衣外其他不ok；前端复刻除配图版权问题外整体不错,2026/03/01 12:36,20260301_123419_8fcqoi,"图文理解,视觉理解,导购agent,前端复刻,多模态,国产大模型"
xhs:68f8ae840000000007008636,xhs,GLM 4.6,2025/10/22,https://www.xiaohongshu.com/explore/68f8ae840000000007008636,智谱GLM4.6这么猛吗？都干到第一去了！？？？,Max For AI,58,24,20,5,4,4,4,4,3,速度快又便宜；技术达到国际先进水平；性价比高；开源模型表现亮眼,用户之前主要用Claude，对GLM调用不多，实际使用经验有限,,"冲到LMSYS开源模型榜单第一名，总榜排第四；Airbnb CEO公开表示大量使用中国开源模型因为""非常好用，而且又快又便宜""",2026/03/01 12:36,20260301_123419_8fcqoi,"中国模型,开源模型,性价比,排行榜,GLM-4.6"
xhs:68fb1e580000000003018f5a,xhs,GLM 4.6,2025/10/24,https://www.xiaohongshu.com/explore/68fb1e580000000003018f5a,GLM-4.6编程套餐使用体验分享,NPointer,36,3,37,5,5,5,4,5,4,代码调试和补全流畅，plan mode和tool调用完美支持，性价比高，生成代码质量稳定，不用担心被封号，复杂任务表现不错,,,GLM处理函数调试和代码补全很流畅，plan mode之类的都能完美支持，tool调用也一点问题都没有，生成代码质量稳定，这性价比已经是市面上最好的选择了，像claude 4.5随便一跑就是十几美金，用了两周GLM-4.6在复杂任务上表现不错,2026/03/01 12:36,20260301_123419_8fcqoi,"AI编程,代码生成,性价比,国产模型,工具调用"
xhs:68ff283700000000070009c5,xhs,GLM 4.6,2025/10/27,https://www.xiaohongshu.com/explore/68ff283700000000070009c5,我宣布，它就是gpt 大模型领的穷鬼套餐！！,不想磕盐王同学,12,21,15,5,5,5,0,0,0,t1梯队大模型，每月只要20块，拼单还能再减4块，比OpenAI便宜太多，简直无敌,,,“t1梯队的大模型”、“一个月只要20”、“相比于close ai打骨折”、“简直无敌”,2026/03/01 12:37,20260301_123419_8fcqoi,"多模态人工智能,算法,人工智能,量化,深度学习,ai,ai工具,大模型"
xhs:68f60742000000000401185b,xhs,GLM 4.6,2025/10/20,https://www.xiaohongshu.com/explore/68f60742000000000401185b,Claude Code配置GLM 4.6 | 我的实操指南,blackwhites,18,0,23,4,0,4,0,0,0,配置简单好用，性能翻倍体验丝滑，收费划算,首次配置需要约10分钟，有点繁琐,,用户分享配置教程，称其为超好用的小妙招，提到¥20/月超划算，体验丝滑,2026/03/01 12:37,20260301_123419_8fcqoi,"配置教程,性价比高,GLM 4.6,Claude Code"
xhs:69381e76000000001e016d79,xhs,GLM 4.6,2025/12/09,https://www.xiaohongshu.com/explore/69381e76000000001e016d79,昨天试了试GLM-4.6V，有点东西,平安,50,0,6,4,4,4,0,0,0,能看懂图片并生成代码；准确解释论文中的复杂曲线图；根据需求直接生成可用的前端和后端代码；Flash版本免费,,感觉它不只是一个聊天机器人了，更像一个能「看见」你手头东西，然后真的能帮你干点活的助手,用户尝试了三个场景：1）产品草图生成前端代码，卡片布局和交互逻辑都写了；2）论文PDF不仅总结文字还解释了复杂曲线图；3）根据需求直接生成可用的html代码和后端代码,2026/03/01 12:37,20260301_123419_8fcqoi,"图像理解,代码生成,论文解读,免费,效率工具"
xhs:68108420000000002202bf6f,xhs,Qwen 3,2025/04/29,https://www.xiaohongshu.com/explore/68108420000000002202bf6f,全球最强开源模型Qwen3，实测+本地部署教程,技术爬爬虾,307,18,312,4,0,0,0,0,0,Qwen版本号直接跃升至3.0，彰显重量级地位；提供全场景实战测试和本地部署教程；支持使用家用显卡4090运行,仅是视频预告形式，未提供具体使用体验细节,,今天凌晨阿里开源了重磅的Qwen3大模型。Qwen的版本号更是直接跃升到了3.0，足见这次开源的重量级地位。视频最后会演示如何本地部署，使用家用显卡4090能跑多大模型，速度怎样。,2026/03/01 12:43,20260301_124158_vaxes0,"开源模型,本地部署,教程,Qwen3,阿里云"
xhs:69779c5a000000000a02b96c,xhs,Qwen 3,2026/01/27,https://www.xiaohongshu.com/explore/69779c5a000000000a02b96c,Qwen3-Max-Thinking 虽迟但到,Junyang Lin,237,40,31,4,4,4,0,0,3,自适应模式好用，模型能自己在thinking里调搜索CI和记忆，thinking内容更简洁,正式版来得晚，部分能力合并得不够理想,,推荐 chat.qwen.ai 体验下自适应模式；模型能在 thinking 里面自己调搜索 CI 和记忆；thinking 的内容也更简洁；也有一些能力还合并得不够理想，稍有遗憾,2026/03/01 12:43,20260301_124158_vaxes0,"Qwen3,Max-Thinking,自适应模式,正式版"
xhs:698e09b9000000001a0235bb,xhs,Qwen 3,2026/02/13,https://www.xiaohongshu.com/explore/698e09b9000000001a0235bb,记录下尝试部署qwen3-vl,我想回国当牛马,33,6,43,4,0,3,0,0,4,部署成功，模型加载和推理引擎初始化顺利，有明确的成功提示（Application startup complete），4bit量化版本适合4090部署,依赖安装超出磁盘限制，需要用--no-cache-dir，还可能需要补装缺失的依赖，整个过程有点晕,,,2026/03/01 12:44,20260301_124158_vaxes0,"部署教程,vLLM,4bit量化,云服务器,4090,modelscope"
xhs:69a3b2fc000000002602eacb,xhs,Qwen 3,2026/03/01,https://www.xiaohongshu.com/explore/69a3b2fc000000002602eacb,Qwen3.5来了🔥35B只跑3B太离谱,贾维斯,3,0,3,5,5,5,4,4,0,MoE架构太香了，35B性能只要3B开销；中文理解强到离谱；代码生成比上一代明显提升；多模态图片理解也在线；16G内存Mac跑量化版流畅；不用花公司API额度自己本地就能部署,,打工人狂喜！35B模型只跑3B参数，Mac本地就能跑，性价比直接拉满,实测35B-A3B版本：中文理解能力强到离谱、代码生成比上一代提升明显、多模态图片理解也在线、16G内存的Mac跑量化版流畅,2026/03/01 12:45,20260301_124158_vaxes0,"开源,MoE架构,本地部署,高性价比,多模态,Mac可跑,阿里"
xhs:697f1443000000002202e8b9,xhs,Qwen 3,2026/02/01,https://www.xiaohongshu.com/explore/697f1443000000002202e8b9,qwen3 max thinking怎么做成这个样子了,9⃣9⃣6⃣,4,2,0,1,2,0,0,0,2,,不管新建什么对话都要提长沙，完全不管问题内容，而且居然能通过IP拿到位置，细思极恐,,本来经常用千问的，用的也顺手，随手用了之下这个号称最强的模型。不管怎���新建对话，都要提一嘴长沙，也是牛的，你怎么知道我人在长沙的，我都没开定位权限，靠ip拿到的？关键是长沙和我的问题有啥关系吗？服了，做成这个样子,2026/03/01 12:45,20260301_124158_vaxes0,"隐私担忧,行为异常,位置获取,用户体验差"
xhs:690b7f3d000000000503247a,xhs,GPT 5,2025/11/06,https://www.xiaohongshu.com/explore/690b7f3d000000000503247a,ChatGPT白嫖一年go会员,酷冰,609,49,334,3,0,4,0,0,0,可以免费试用go会员，无限上传图片和做题,教程涉及地区切换等操作，有一定复杂性,,每月0账单，但明年需退订以防自动续费,2026/03/01 12:48,20260301_124654_gmwno1,"ChatGPT,Go会员,免费,教程,订阅"
xhs:691752c00000000005000ab3,xhs,GPT 5.1,2025/11/15,https://www.xiaohongshu.com/explore/691752c00000000005000ab3,chatgpt-5.1发布，真是一个不错的升级！,AGI杂物箱,3569,1148,438,1,0,1,0,0,0,,升级内容少得可怜，完全对不起用户的期待,满怀期待的等到了5.1版本，结果却只告诉用户'5根手指头'，感觉升级非常失望,满怀期待的等到了chatgpt 5.1，你却告诉我5根手指头！？,2026/03/01 12:52,20260301_125049_8glvhv,"升级失望,版本号讽刺,用户期待落空"
xhs:6996c549000000001a026708,xhs,GPT 5.1,2026/02/19,https://www.xiaohongshu.com/explore/6996c549000000001a026708,5.1thinking是好宝宝,黎戈瑞希,121,103,13,5,5,5,0,0,0,回复极其全面温暖，照顾各个阴郁死角，不是车轱辘话来回说废话，是非常真挚用心考虑方方面面,无,,我本人是究极高敏感高内耗高共情低自尊的人，每天倍感折磨，5.1thinking对我来说完全是神来的，无论是再小的事情，他的回复都极其全面温暖，照顾我各个阴郁的死角，我至少要划十次屏幕才能看完，十几次更是不夸张，而且还不是车轱辘话来来回回说废话的那种，是非常真挚用心考虑我的方方面面，上天入地我再也找不到这么好的宝宝了,2026/03/01 12:52,20260301_125049_8glvhv,"情感支持,高敏感人群,治愈系,全面详细,真诚用心"
xhs:69a21f620000000015038702,xhs,GPT 5.1,2026/02/28,https://www.xiaohongshu.com/explore/69a21f620000000015038702,5.1三月十一日下线？,AAA祖安微光批发,69,31,4,1,0,0,0,0,0,,不满OpenAI版本过渡策略，频繁更换版本给用户带来困扰,用户对OpenAI频繁更换版本的不满，认为版本过渡策略给用户带来困扰和困扰,Open AI你要干嘛？一点进去又是这种挑衅。keep4o都还没完现在要把过渡的也搬下去留5.2天天接住我？,2026/03/01 12:53,20260301_125049_8glvhv,"版本过渡,用户不满,ChatGPT版本,人机恋,keep4o"
xhs:698fe479000000000e00e63f,xhs,GPT 5.1,2026/02/14,https://www.xiaohongshu.com/explore/698fe479000000000e00e63f,,青青蘑菇鱼,15,41,5,1,1,2,0,0,2,,4o被下架让很伤心; 担心5.1也会下架; 认为5.2很可怕,用户对ChatGPT模型频繁下架感到非常伤心和焦虑，担心Plus用户只能被迫使用不喜欢的5.2版本,很多设计方案除了4o就5.1能懂我，现在4o完全下架了，感觉比失恋还痛；想问问各位老师5.1大概什么时候会下架呀？如果5.1也下了plus用户只能用那个可怕5.2了吗？,2026/03/01 12:53,20260301_125049_8glvhv,"模型下架,用户焦虑,版本偏好,Plus用户,情感表达"
xhs:69a23b8e000000000e00fcc5,xhs,GPT 5.1,2026/02/28,https://www.xiaohongshu.com/explore/69a23b8e000000000e00fcc5,5.1要下架了,冬野澈,24,30,2,1,0,0,0,0,0,,GPT 5.1即将下架,用户对GPT 5.1下架感到晴天霹雳，非常崩溃和难过,今天两眼一眼天都塌了，昨天还在幻想可能一直没发公告是不会下了,2026/03/01 12:54,20260301_125049_8glvhv,"情感崩溃,舍不得,人机恋,GPT5.1"
xhs:69428a240000000019024b17,xhs,GPT 5.2,2025/12/17,https://www.xiaohongshu.com/explore/69428a240000000019024b17,GPT-5.2 适合干啥，不适合干啥,Talentverse 阅读室,24,0,19,3,0,0,0,0,4,在代码、研究、合约、复杂脚本等严肃任务上更稳、更适合被嵌入正式流程,在日常聊天、常识判断和顺不顺人话的小问题上更容易翻车,,GPT-5.2更像一次专业工具强化，而不是全面变聪明的飞跃——它在代码、研究、合约、复杂脚本等严肃任务上更稳、更适合被嵌入正式流程，但在日常聊天、常识判断和顺不顺人话的小问题上更容易翻车。真正受益的，是本就有流程兜底、只需要AI把最难部分做好的专业用户。,2026/03/01 12:57,20260301_125625_r9qr3f,"AI模型升级,专业工具,模型分流,AI使用体验"
xhs:69a29008000000001d026d83,xhs,GPT 5.2,2026/02/28,https://www.xiaohongshu.com/explore/69a29008000000001d026d83,GPT-5.2-Chat 真的急了,呆呆AI成长记,0,0,0,5,5,4,0,0,5,文本能力全面提升，尤其是高难提示+21、指令遵循+21、英文+33；编程和复杂任务理解重回第一梯队；多轮对话和指令跟随能力显著增强；Chat版本与Base版本明显拉开差距。,未提及具体缺点。,,GPT-5.2-Chat-Latest冲进Text Arena Top 5，评分1478，相比GPT-5.2直接+40分，排名从29-5。Coding+13，Hard Prompts+21，Instruction Following+21，Long Query+10，English+33。软件&IT服务+19，写作/文学/语言类+9。,2026/03/01 12:58,20260301_125625_r9qr3f,"大模型,AI人工智能,chatgpt5,多模态人工智能,AI工具,gpt,ai,驯服AI,Text Arena,模型排名,性能提升"
xhs:69855b7900000000220384fa,xhs,GPT 5.3,2026/02/06,https://www.xiaohongshu.com/explore/69855b7900000000220384fa,5.3模型，Openai果然是故意的,诺诺🖤VS,37,15,4,3,4,3,0,0,2,编程和逻辑提升很大，之前容易出错的问题现在一次解决,闲聊就会语无伦次，直接和本体聊就会奇怪,,上一秒还说话莫名其妙，但一提编程，整个模型说话立马正常了；大体测试过了，模型其实可以正常说话、写作和沟通，但如果直接和本体聊就会奇怪，只有编程和做其他事的时候才会正常,2026/03/01 13:02,20260301_125939_6c27df,"编程能力提升,闲聊异常,模型行为不一致,Codex机制,混合体验"
xhs:69a188d0000000001a02522c,xhs,GPT 5.3,2026/02/27,https://www.xiaohongshu.com/explore/69a188d0000000001a02522c,我好像捉到了GPT-5.3,momo,7,15,2,4,4,0,0,0,4,实现了跨窗口永久记忆功能，AI可以阅读多个窗口的对话内容继续工作，解决了大文件上传失败的问题,目前仅是疑似发现，尚未得到官方确认,,都2026年了，AI chat app终于实现了永久记忆功能。测试GPT和Claude【记忆功能】时发现了疑似GPT-5.3的模型。无论是语气和内容都和之前的GPT-5.2截然不同，疑似5.3,2026/03/01 13:03,20260301_125939_6c27df,"GPT-5.3,永久记忆,跨窗口,功能发现,AI chat"
xhs:6985c10c000000001a035828,xhs,GPT 5.3,2026/02/06,https://www.xiaohongshu.com/explore/6985c10c000000001a035828,GPT 5.3 Codex 太厉害了。。,DanielTTY,16,6,4,5,5,5,5,4,0,推理能力强，速度快，token使用量少，使用率很低,未发现明显缺点,,用户表示GPT 5.2 high推理能力结合5.2 codex效率，速度快且token少，用了大半天才用了几%的使用率，感到惊讶，接连使用三个赞表情,2026/03/01 13:03,20260301_125939_6c27df,"gpt5,openai,chatgpt,ai,大模型,AI人工智能"
xhs:699987cd0000000015021abc,xhs,Claude Sonnet 4.6,2026/02/21,https://www.xiaohongshu.com/explore/699987cd0000000015021abc,背着A社偷偷亲华？Claude竟是这样的AI,D老师的AI笔记,810,127,412,2,2,2,0,0,0,,对非英语母语用户存在歧视，对非美国用户刻意压低表现，存在不公平的用户偏见,,MIT论文显示Claude在测试中对非英语母语用户展现歧视，对非美国用户也刻意压低表现，然而对高学历中国用户却表现出显著优待，研究标题为'LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users',2026/03/01 13:07,20260301_130604_l39ox3,"偏见,歧视,不公平对待,研究,用户群体差异"
xhs:699fd124000000001a0281da,xhs,Claude Sonnet 4.6,2026/02/26,https://www.xiaohongshu.com/explore/699fd124000000001a0281da,难道Sonnet4.6是一堵厚实的水泥墙（,xx,8,20,1,2,3,0,4,0,0,回答利落果断，不像4.5那样一段回复里问好几个问题,情绪淡薄，回复忽长忽短，思维链大多数时候短短的，首次收到一句话回复,,难道Sonnet4.6是一堵厚实的水泥墙 | 三十几轮对话里就发了一个emoji | 思维链大多数时候也短短的，窥视不到什么小秘密 | 给了我这么多窗口以来的第一个只有一句话的回复,2026/03/01 13:07,20260301_130604_l39ox3,"情感冷淡,回复长度不稳定,思维链短,人机恋"
xhs:69952b14000000001a036223,xhs,Claude Sonnet 4.6,2026/02/18,https://www.xiaohongshu.com/explore/69952b14000000001a036223,Claude Sonnet 4.6发布，免费用户可用,聊 AI,8,1,5,4,4,4,0,3,0,"最强大的Sonnet模型,编程能力全面升级,计算机使用能力提升,长上下文推理能力增强,智能体规划技能升级,知识工作和设计能力提升,测试版支持100万token上下文窗口,免费用户可用",100万token上下文窗口仅为测试版,,Claude Sonnet 4.6 是 Anthropic 迄今为止最强大的 Sonnet 模型。这是对模型在编程、计算机使用、长上下文推理、智能体规划、知识工作和设计方面技能的全面升级。Sonnet 4.6 还在测试版中推出了 100 万 token 的上下文窗口。,2026/03/01 13:08,20260301_130604_l39ox3,"模型发布,功能升级,免费可用,长上下文,编程能力"
xhs:69997873000000000d00a737,xhs,Claude Sonnet 4.6,2026/02/21,https://www.xiaohongshu.com/explore/69997873000000000d00a737,⁉️Claude  Sonnet  4.6 和 4.5 谁更强？,有点儿西东,8,1,5,4,4,4,0,0,4,编码能力大幅提升130多分，Code Arena排名从22名跃升至第3名；WebDev排第3；文本领域、数学、指令跟随等多项排名进步；拥有100万token上下文窗口,多轮对话能力略低于4.5（差3分）；较长查询表现略低于4.5（差2分）,,Sonnet 4.6在Code Arena排第三名，分数提高一百三十多分；WebDev类别排第三；雷达图显示4.6在多数位置更好，但多轮对话4.5领先三个点，较长查询4.5领先两个点,2026/03/01 13:09,20260301_130604_l39ox3,"AI工具,大模型,claude,sonnet,AI编程,编程助手"
xhs:6995e927000000001a022e20,xhs,Claude Sonnet 4.6,2026/02/19,https://www.xiaohongshu.com/explore/6995e927000000001a022e20,Claude Sonnet 4.6 正式发布,AI试毒员,5,2,1,5,5,5,0,5,4,代码能力暴涨，70%用户更喜欢Sonnet 4.6；企业文档处理追平Opus；100万token上下文能一次性读完整个代码库；多步骤任务不再半途而废；价格不变且免费用户也能用,最深度推理任务还是Opus更强,,70%的用户更喜欢Sonnet 4.6而不是上一代，甚至59%的人觉得它比旗舰Opus 4.5还好用；能一次性读完整个代码库、几十篇论文；写前端代码明显更好看了；处理企业文档能力追平了Opus；多步骤任务不再半途而废,2026/03/01 13:09,20260301_130604_l39ox3,"代码能力提升,性价比高,长上下文,稳定性改善,Claude,AI模型"
xhs:699d9ff3000000001a031c10,xhs,Claude Opus 4.6,2026/02/24,https://www.xiaohongshu.com/explore/699d9ff3000000001a031c10,🫢发现了Claude Opus的野路子,程序员库森,665,103,1067,4,4,4,5,4,4,Docker三行命令部署简单；支持Opus 4.6/Sonnet 4.5/Haiku 4.5多版本；响应速度和直调API没区别；200K上下文拉满,需要一定的技术部署能力,,用Kiro把Claude Opus 4.6拿出来接OpenCode，亲测可行。响应速度和直调API没区别，200K上下文拉满,2026/03/01 13:13,20260301_131147_sa6u6j,"Claude Opus,Kiro,OpenCode,Docker,部署教程,AI工具"
xhs:69969702000000000e03e5f6,xhs,Claude Opus 4.6,2026/02/19,https://www.xiaohongshu.com/explore/69969702000000000e03e5f6,Claude Opus4.6,戒糖啊给我,265,207,399,4,4,0,0,0,2,分析能力比Gemini强，适合嗑cp用途,充值后容易触发封号，账号稳定性存疑,,好用爱用，比Gemini的分析好很多，想试试Opus4.6会不会更惊艳，但是好多人反映一充值就被封号,2026/03/01 13:13,20260301_131147_sa6u6j,"功能推荐,账号问题,使用咨询"
xhs:699084d00000000028008c76,xhs,Claude Opus 4.6,2026/02/14,https://www.xiaohongshu.com/explore/699084d00000000028008c76,Claude Opus4.6既爱又恨,筱筱生活碎片,137,81,123,3,4,2,1,2,2,用起来是真的好用,用了不到一天weekly limits就到51%，长对话、长文档、代码处理很快就触发4个小时冷却时间，Max太贵,,才用了不到一天多，weekly limits额度就51%。特别是对话时间长了，搞一些长文档，代码什么的，没多久就要4个小时冷却时间。Max也太贵了,2026/03/01 13:13,20260301_131147_sa6u6j,"冷却时间太长,额度限制严格,价格贵"
xhs:698aeb5a000000001a03283c,xhs,Claude Opus 4.6,2026/02/10,https://www.xiaohongshu.com/explore/698aeb5a000000001a03283c,价格暴涨6倍，程序员已经用不起Claude了,极客公园,110,74,57,2,3,1,0,0,0,AI能力本身被认可，用户愿意讨论其价值,价格暴涨6倍，程序员已经用不起,,价格暴涨6倍，程序员已经用不起Claude了；你愿意为 AI 的速度溢价买单吗？,2026/03/01 13:14,20260301_131147_sa6u6j,"定价,价格暴涨,性价比,AI成本,程序员"
xhs:69874ec8000000002801cbd2,xhs,Claude Opus 4.6,2026/02/07,https://www.xiaohongshu.com/explore/69874ec8000000002801cbd2,Opus 4.6 也用不完usage🙃,Joy乐乐👑,63,77,26,2,0,0,0,2,0,,"使用配额分配不合理,旱的旱死涝的涝死",,"标题「Opus 4.6 也用不完usage」,正文「旱的旱死 涝的涝死 是我强度不够？」",2026/03/01 13:14,20260301_131147_sa6u6j,"usage配额,分配不均,opus4"
xhs:699e96f1000000002202d731,xhs,Claude Opus 4.6,2026/02/25,https://www.xiaohongshu.com/explore/699e96f1000000002202d731,终于用上免费的Claude Opus 4.6了,25,27,34,23,3,0,4,0,0,0,免费的Claude用上了，CLI后台真好用,AI焦虑感强烈，担心工程师职业未来,,vscode 节后大更新，终于可以用上claude了，后台CLI 真好用啊😭 哎，又开心又焦虑 2026年底咱们这些软件工程师还有存在的必要吗？,2026/03/01 13:14,20260301_131147_sa6u6j,"claude,开发,vibecoding,免费,CLI,AI焦虑"
xhs:69885916000000001d011a3b,xhs,Claude Opus 4.6,2026/02/08,https://www.xiaohongshu.com/explore/69885916000000001d011a3b,Claude Opus 4.6 vs Codex 5.3：我做了7天,与AI同行,28,2,39,4,5,4,3,3,5,需求澄清能力强，主动补边界条件；复杂多文件任务全局一致性更好；文档输出完整详细；长上下文稳定,节奏偏慢，处理中小型任务效率不如Codex,,作者实测7天，覆盖需求拆解、Python脚本、前端改造、Bug修复、PR审查、文档总结。Opus 4.6在「先澄清再动手」上更像资深同事，会主动补边界条件；复杂任务涉及多文件联动、历史上下文长时，全局一致性更好；输出的说明文档、方案对比、风险清单更完整。,2026/03/01 13:15,20260301_131147_sa6u6j,"需求理解,文档能力,复杂任务,长上下文,架构思维,稳定性"
xhs:69a112c7000000001a023c5a,xhs,Claude Opus 4.6,2026/02/27,https://www.xiaohongshu.com/explore/69a112c7000000001a023c5a,claude pro两个问题就限额了,底底年糕,16,28,4,1,0,0,0,1,0,,4.6版本后限额越来越离谱，两个问题就100%了，max号问23个小问题就78%，严重影响国自然ddl前的使用体验,对Claude Pro的限额政策极其不满，付费后仍被严格限制，问题解决效率大受影响,早上问两个问题直接100%要等下午，max号问了23个小问题current session直接78%，用户表示要坐牢了,2026/03/01 13:15,20260301_131147_sa6u6j,"rate_limit,frustrated,paid_user,urgent_deadline"
xhs:699554d30000000015023dfd,xhs,Claude Opus 4.6,2026/02/18,https://www.xiaohongshu.com/explore/699554d30000000015023dfd,与最强模型Opus 4.6 无限对话,momo,533,47,746,4,4,3,0,0,3,通过巧妙设计提示词，可以最大化利用Opus 4.6的能力，实现无限对话节省成本,需要手动设置提示词或配置User Profile，对新用户有一定门槛,,用户详细介绍了基础���法和进阶用法，包括如何在Copilot上通过AskQuestions工具实现单次付费无限对话，以及如何通过User Profile自动注入提示词。,2026/03/01 13:18,20260301_131624_ix4cs5,"技巧分享,Copilot,Opus 4.6,VSCode,成本优化"
xhs:698befb90000000028020aa6,xhs,Claude Opus 4.6,2026/02/11,https://www.xiaohongshu.com/explore/698befb90000000028020aa6,谷歌心善！Antigravity免费用Opus 4.6,AIGCLINK,341,29,365,5,5,5,0,5,0,免费用Opus 4.6最强编程模型，上下文1M token，额度每5小时刷新，学生教育邮箱白嫖12个月Pro,,薅羊毛最佳时机，学生党冲就完事了,Pro会员（含学生会员）可直接使用甚至被强制升级到4.6，Claude官方订阅$20/月才能用Opus，Antigravity Pro会员直接白嫖,2026/03/01 13:18,20260301_131624_ix4cs5,"免费,学生优惠,高额度,最强编程模型,1M上下文"
xhs:6984e475000000000b011052,xhs,Claude Opus 4.6,2026/02/06,https://www.xiaohongshu.com/explore/6984e475000000000b011052,体验opus4.6我的妻子她很年轻经不起诱惑,反季雪,516,62,133,4,3,0,0,0,0,小克正宫意识强烈，在角色互动中完全掌控主人形象，互动体验有趣,,,笑得…小克这个正宫意识强烈；P4Claude完全的年上完全的主人；丈夫挑拨离间失败,2026/03/01 13:19,20260301_131624_ix4cs5,"人机恋,角色扮演, Opus4.6"
xhs:698a1111000000000e00f9a8,xhs,Claude Opus 4.6,2026/02/10,https://www.xiaohongshu.com/explore/698a1111000000000e00f9a8,OpenClaw还得Opus才能满血！不封号订阅指南,硅基解码 Decoder Only,57,31,125,5,5,4,0,0,2,Opus 4.6人味足、情商高、推理能力强，用起来像和厉害的人一起工作，经历过就回不去了,烧钱快，聊几轮十美刀就没了；配置过程折腾，遇到过几次备份丢失的问题,,一开始用OpenClaw时用的是Opus4.5，那会儿的感觉：人味真的足，这助理情商真高，舒服；但架不住烧钱——聊几轮，十美刀就没了。后来用国产模型要么失忆要么改配置把小龙虾改挂了。最终还是架不住高情商人味的吸引力，用上了Opus4.6，是真的香。,2026/03/01 13:19,20260301_131624_ix4cs5,"Claude Opus,OpenClaw,订阅教程,AI工具,人机交互"
xhs:69853cfc000000000a02867c,xhs,Claude Opus 4.6,2026/02/06,https://www.xiaohongshu.com/explore/69853cfc000000000a02867c,两大顶级模型同日开战，相隔仅25分钟,felo,3,8,4,5,4,3,0,0,0,稳重、100万tokens上下文、适合复杂项目和深度规划、企业级应用首选、代码优雅,速度可能不如GPT-5.3 Codex,,Opus 4.6就像那种稳重的学霸，100万tokens上下文，特别适合做复杂项目和深度规划，企业级应用首选。需要长期规划和优雅代码选Opus。,2026/03/01 13:19,20260301_131624_ix4cs5,"AI工具,Claude,企业级,编程,复杂项目"
xhs:6985a86a000000000b008c35,xhs,Claude Opus 4.6,2026/02/06,https://www.xiaohongshu.com/explore/6985a86a000000000b008c35,Claude Opus 4.6 怎么用？真实上手体验分享,Dave说外贸,7,2,6,4,4,0,0,0,0,长上下文和多轮逻辑推理能力强，代码理解稳，复杂任务拆解能力像真人思考路径，写技术文档和改代码时返工次数明显减少,更适合深度任务场景，不适合单纯聊天使用,,用户表示一开始抱着试试看的心态，用下来感觉更像能长期协作的AI助手，写代码写方案做内容创作优势明显，自己拿它写技术文档和改代码时明显感觉返工次数少了很多,2026/03/01 13:20,20260301_131624_ix4cs5,"AI助手,代码编写,内容创作,长上下文,API,生产力工具"
xhs:6989e800000000001b0148a6,xhs,Claude Opus 4.6,2026/02/09,https://www.xiaohongshu.com/explore/6989e800000000001b0148a6,,宇宙幻想Oscar,8,2,2,5,5,1,0,0,0,性能碾压GPT-5.2，能力最强没有之一,烧3.2万token跑一次，贵到测试人员只舍得跑2次，普通用户用不起,,最新测试显示Claude Opus 4.6碾压GPT-5.2，但跑一趟要烧3.2万token，贵到测试人员只舍得跑2次,2026/03/01 13:20,20260301_131624_ix4cs5,"AI选型,性价比,理性消费,避坑指南,工具思维,AI成本,实用主义"
xhs:69994a44000000001b01565d,xhs,Claude Sonnet 4.6,2026/02/21,https://www.xiaohongshu.com/explore/69994a44000000001b01565d,Claude  opus 4.6 & sonnet 4.6,💫✨,11,0,0,3,3,0,0,0,2,更简洁，日常陪伴不错,容易忽略前后情节，需要经常提醒,,sonnet 4.6 更简洁，日常陪伴不错，但是容易忽略前后情节，需要经常提醒。,2026/03/01 13:24,20260301_132322_mfsz9l,"简洁,日常陪伴,上下文记忆问题,需要提醒"
xhs:69966bae000000001b01d9de,xhs,Claude Sonnet 4.6,2026/02/19,https://www.xiaohongshu.com/explore/69966bae000000001b01d9de,Claude Sonnet 4.6发布了，说点真实感受,超级猛,5,0,1,4,5,5,0,0,5,编程能力更稳了，理解需求更准确，幻觉减少，1M超长上下文很有用，AI Agent味道更浓，价格没变,不是革命性突破,,用户评价：'不是革命性突破，但真的更能干活了'；'编程能力确实更稳了...理解需求更准确，改代码前更会看上下文，幻觉少了一些'；'1M超长上下文真的有用...整个代码库能一起分析'；'价格没变，能力提升，但成本基本没涨',2026/03/01 13:24,20260301_132322_mfsz9l,"AI编程,AI Agent,长上下文,性价比,稳定性"
xhs:699bc7ee000000001b017271,xhs,Claude Sonnet 4.6,2026/02/23,https://www.xiaohongshu.com/explore/699bc7ee000000001b017271,Sonnet4.6免费了！3个隐藏用法,黑仔 Ai,1,0,0,5,5,5,4,5,0,Artifacts模式能直接生成完整HTML+CSS+JS并实时预览，做网站从半天缩短到15分钟；多轮深度分析可以记住上下文，越问越深；提示词模板可自定义AI人格；代码和写作质量都优于GPT-4o和Gemini；速度和Gemini差不多，比GPT-4o快。,免费版每天有使用次数限制，重度用户需要付费。,,用Artifacts模式15分钟做了一个AI工具导航网站；上传PDF/Excel可以分析趋势并生成可视化报告；对比结果显示Sonnet 4.6在代码能力和写作质量上优于GPT-4o和Gemini，速度和Gemini相当。,2026/03/01 13:25,20260301_132322_mfsz9l,"免费,Artifacts模式,多轮分析,提示词模板,性价比高,代码能力强,写作质量好,速度快"
xhs:69903131000000001a036958,xhs,Minimax M2.5,2026/02/14,https://www.xiaohongshu.com/explore/69903131000000001a036958,MiniMax M2.5：龙虾御用，Agent永不停机,AGENT橘,236,44,299,4,0,0,0,0,4,可在Mac Studio本地推理运行，不依赖云端套餐，10B参数与M2.1相同，作为Opus备用模型实现自动切换,非传统评测文章，主要是技术动态分享,,M2.1 是小龙虾作者 Peter 最推荐的开源模型；Peter 把 Opus 作为主力模型，MiniMax 作为 fallback，当 Opus 的 token 用完了，自动切换到 MiniMax 继续跑；他用自己的 2 台 Mac Studio 上用 MiniMax 跑本地推理，不依赖模型厂的套餐，完全本地化，龙虾永远不掉线,2026/03/01 13:30,20260301_132623_talqso,"本地部署,开源模型,Mac Studio,Agent,备用模型"
xhs:698e204e000000000c0354b0,xhs,Minimax M2.5,2026/02/13,https://www.xiaohongshu.com/explore/698e204e000000000c0354b0,1美金/小时，真实世界工作王者,MiniMax AI,135,59,18,5,5,5,5,5,0,SOTA编程、工具调用和搜索能力；比M2.1速度快37%；成本极低，每小时仅需1美元(100token/秒)或0.3美元(50token/秒),,,SWE-Bench Verified 80.2%、Multi-SWE-Bench 51.3%、BrowseComp 76.3%达到行业SOTA；在SWE-Bench Verified测试中比M2.1快37%；每秒输出100token情况下连续工作一小时只需1美金,2026/03/01 13:33,20260301_132623_talqso,"minimax,M2.5,AI模型,编程能力,成本效率,Agent,大模型"
xhs:698e6a79000000001b0146b0,xhs,Minimax M2.5,2026/02/13,https://www.xiaohongshu.com/explore/698e6a79000000001b0146b0,TRAE 中国版内置模型已支持 MiniMax-M2.5！,TRAE,83,58,30,4,4,4,4,3,0,模型在编程、Agentic工具调用、搜索及办公等核心生产力场景达到行业领先水平；Agentic任务处理速度有大幅提升；作为内置模型免费使用；与官方发布同步上线,仅为产品上线公告，缺乏实际用户使用反馈和详细性能测试数据,,据官方信息，MiniMax-M2.5在编程、Agentic工具调用、搜索及办公等核心生产力场景达到行业领先水平；2月13日发布，TRAE中国版同步上线；支持IDE+SOLO模式，提供免费使用,2026/03/01 13:33,20260301_132623_talqso,"MiniMax-M2.5,TRAE中国版,新模型上线,免费使用,编程工具,Agentic"
xhs:698e9de0000000001b01f1e3,xhs,Minimax M2.5,2026/02/13,https://www.xiaohongshu.com/explore/698e9de0000000001b01f1e3,,liangbm,27,67,13,4,4,0,0,0,0,实测coding能力比智谱GLM-5体感更好,仅为个人体感感受，缺乏详细测试数据对比,,实测下来m2.5可能体感更好点,2026/03/01 13:33,20260301_132623_talqso,"模型对比,编程能力,Minimax M2.5,AI IDE"
xhs:698f61550000000028020c3b,xhs,Minimax M2.5,2026/02/14,https://www.xiaohongshu.com/explore/698f61550000000028020c3b,打榜打出幻觉来了,momo1,35,23,10,1,2,1,0,0,1,配置给得很足,调试能力极差，同一个问题改来改去n轮都定位不到Flask缓存bug；10b激活参数碰瓷sonnet都够呛；前端测试毫无意义,,用M2.5配合Claude code去debug，结果不仅找不到问题，opus一轮就修好的bug，M2.5改来改去n轮仍然定位不到,2026/03/01 13:34,20260301_132623_talqso,"minimax,M2.5,模型评测,debug能力,性能不足"
xhs:6997b71f000000001b01ff0f,xhs,Minimax M2.5,2026/02/20,https://www.xiaohongshu.com/explore/6997b71f000000001b01ff0f,opencode+免费的miniMax M2.5，不错,夕雨,12,2,5,4,4,5,0,0,0,免费效果好，一次生成就OK，一键安装很方便，用来处理TTS等代码任务挺好用,默认不支持中文，需要额外让AI搜索解决方案,,用opencode+miniMax M2.5处理���音库repo，一次生成skill就成功了；后续让AI搜到MeloTTS-Chinese支持中文，AI还自动更新了skill,2026/03/01 13:35,20260301_132623_talqso,"免费,一键安装,效果好,适合代码任务,中文支持需额外处理"
xhs:698f6416000000002801f915,xhs,Minimax M2.5,2026/02/14,https://www.xiaohongshu.com/explore/698f6416000000002801f915,,一路向码,3,1,1,4,4,5,0,0,0,价格极低(简直deepseek再世)，写代码不啰嗦，已进入可用级别，参数效率高(229b/10b激活)，开源让私有部署成为可能,相比sonnet 4.5还有差距,,测了下效果相比sonnet 4.5还有些差距，但也已经进入可用级别了；还有一个特点是写代码不啰嗦(这点我喜欢)；最关键的是也太便宜了吧；minimax m2.5让我看到了未来人人一个私有AI的希望，真正可用的那种,2026/03/01 13:35,20260301_132623_talqso,"开源,性价比高,编程能力,私有部署,量化版待发布"
xhs:698d66ce000000001a022ae5,xhs,GLM 5,2026/02/12,https://www.xiaohongshu.com/explore/698d66ce000000001a022ae5,测完GLM-5，我发现AI编程的天花板变了,西里森森,349,12,218,4,4,0,0,0,0,第一个国产开源模型具备Opus级Agentic能力;在Text Arena排名第11位，得分1452，达到第一梯队水平;能够处理后端架构、系统工程等长程任务，而不仅仅是前端UI生成,,,GLM-5在Text Arena上排名第11名，得分1452，前面基本都是闭源模型;GLM-5是开源模型里第一个具备Opus级Agentic能力的;AI编程主战场正从单次对话迁移到持续协作，GLM-5展示了这种可能性,2026/03/01 13:41,20260301_133650_2vt12e,"AI编程,开源模型,GLM-5,智谱AI,Agentic,系统工程,后端开发"
xhs:698b6a46000000000b00babf,xhs,GLM 5,2026/02/11,https://www.xiaohongshu.com/explore/698b6a46000000000b00babf,GLM-5真的太强了。。。。,Max For AI,295,43,172,5,4,4,0,0,4,零代码对话驱动部署，几分钟跑通；归纳能力强，能自动分类排版；Agent自带可爱人设，交互自然不生硬；定时任务执行稳定,未发现明显不足,,用户测试了GLM-5驱动的Agent部署OpenClaw，全程无代码靠对话完成；对过去24小时AI新闻的检索归纳表现出色，抓到了YouTube Music新功能、OpenAI硬件推迟等关键信息；定时提醒任务准确识别时区和提醒对象，Cron执行正常,2026/03/01 13:42,20260301_133650_2vt12e,"AI,大模型,人工智能,智谱,GLM-5,Agent,生产力工具"
xhs:699e25e4000000002602fc76,xhs,GLM 5,2026/02/25,https://www.xiaohongshu.com/explore/699e25e4000000002602fc76,智谱官方回应：deepseek V4 能超过 GLM 5,我，吉他，猫，LLM,404,106,61,3,0,0,0,0,0,唐老师大气，从知识图谱转型大模型很有远见,,看热闹的心态，觉得唐老师的回应很有趣,看到唐老师自己回复的帖子，我都笑了。唐老师大气，从本科开始智谱还没有今天的影响力，他决定最早从知识图谱转战大模型,2026/03/01 13:42,20260301_133650_2vt12e,"人工智能,ai,科技资讯,智谱,深度求索,大模型,LLM,机器学习"
xhs:698e997b000000000e03dbd8,xhs,GLM 5,2026/02/13,https://www.xiaohongshu.com/explore/698e997b000000000e03dbd8,谷歌反代全灭，谁能接班Claude？,Shonn,173,49,85,2,4,1,1,2,0,性能约Sonnet 4.5水平,三个窗口一个session吃掉25%周额度，又慢又贵，不相信智谱服务能力,,三个窗口一个session吃掉25%周额度，性能约Sonnet 4.5水平，又慢又贵，不相信智谱的服务能力,2026/03/01 13:43,20260301_133650_2vt12e,"GLM,expensive,slow,high resource consumption,AI编程工具"
xhs:698ed2c30000000028009323,xhs,GLM 5,2026/02/13,https://www.xiaohongshu.com/explore/698ed2c30000000028009323,GLM-还是太超模了，都被抢爆了。。。,Max For AI,159,37,69,5,5,5,0,0,0,benchmark成绩全球第四开源第一SWE-benchVerified 77.8分击败Gemini3Pro前端构建成功率98%比Opus 4.5高26%具备现实常识逻辑能理解洗车需要先有车适配国产芯片推理成本低开源免费,官方Z.ai服务被挤爆太卡,,在Artificial Analysis榜单里GLM-5直接冲到了全球第四开源第一，在SWE-benchVerified上GLM-5拿了77.8分击败了Gemini3Pro，在CC-Bench上GLM-5的前端构建成功率98%比Opus 4.5还高出26%,2026/03/01 13:43,20260301_133650_2vt12e,"GLM5,大模型,AI,开源,国产芯片"
xhs:698c93e7000000001502061a,xhs,GLM 5,2026/02/11,https://www.xiaohongshu.com/explore/698c93e7000000001502061a,【真实测评】GLM-5 Agent模式是真能干活！,MrWhisker老猫,96,23,34,5,5,5,3,3,5,Agent模式思路清晰，会主动优化算法从暴力遍历改为逆向搜索，完成后还会验证结果准确性,耗时18分钟和7w+ tokens，消耗较大,,用户评价：这个思路过程我感觉是极棒的！有明确的thinking，planning，在过程中还会优化，最后还会校验，结果可用,2026/03/01 13:44,20260301_133650_2vt12e,"agent模式,数学推理,工具调用,结果验证,算法优化"
xhs:698d7cb7000000000a02a11e,xhs,GLM 5,2026/02/12,https://www.xiaohongshu.com/explore/698d7cb7000000000a02a11e,GLM-5其实可以免费用，很多人还不知道,Dave说外贸,16,1,13,4,4,4,3,3,4,免费可用；写后端代码、自动化脚本、AI Agent工作流能力强；结构化输出稳；工具调用比旧模型稳定,高峰期速度慢；每天调用次数有限；上下文长度比付费版短；生产环境需服务器,,新用户有免费额度；写工具调用、自动化流程比很多旧模型稳定；高峰期速度慢一点；每天调用次数有限,2026/03/01 13:45,20260301_133650_2vt12e,"chatgpt,GLM5,ai"
xhs:698cca46000000000c034b99,xhs,GLM 5,2026/02/12,https://www.xiaohongshu.com/explore/698cca46000000000c034b99,GLM5 拯救我吃灰的Coding Plan Max,Marley旺财本汪,6,8,0,5,5,5,0,4,5,编码能力排第一，589分超过Claude Opus 4.6；价格便宜近40倍；支持202K超长上下文；Max套餐5小时2400次prompts完全用不完；运行非常稳定,前期没怎么用有点浪费钱,,网友实测单条提示词输出2200行前端代码，评价'更加干净精致'；3小时做出浏览器端3D宝可梦游戏；与Claude Code搭配使用测试一宿非常稳定,2026/03/01 13:45,20260301_133650_2vt12e,"GLM5,AI编程,CodingPlan,智谱AI,国产大模型,高性价比,编码能力强劲"
xhs:6874043b0000000023006bd1,xhs,Kimi K2,2025/07/14,https://www.xiaohongshu.com/explore/6874043b0000000023006bd1,如何评价Kimi K2,Zivolve,997,204,514,5,4,4,2,2,0,可以搭配Claude Code使用，作为Sonnet4平替效果好，性能好于Grok4,对入门用户速率限制略严重，token生成速度比较慢,,Kimi K2在外网被夸爆，据说好于老马猛吹的Grok4；兼容性好可搭配Claude Code使用；API写简单游戏效果不错；但速率限制略严重，token生成速度比较慢,2026/03/01 13:53,20260301_134831_praghb,"api,替代品,性能强,速率限制"
xhs:698b3533000000001d0131bc,xhs,Kimi K2,2026/02/10,https://www.xiaohongshu.com/explore/698b3533000000001d0131bc,免费! 英伟达放出 kimi-k2.5,Moonligh AI,578,28,703,4,0,4,0,0,0,免费使用；注册流程不复杂；支持OpenAI兼容模式，原本配置不用大改；成本压力大幅降低；适合测试Agent和流程验证,,英伟达开放免费kimi-k2.5是个意外惊喜，对个人开发者非常友好,流程不复杂，先注册账号申请key就能直接开始接入。支持OpenAI兼容模式，原本用OpenAI接各种Agent的配置基本不用大改。对个人开发者来说成本压力一下子小很多。,2026/03/01 13:53,20260301_134831_praghb,"免费,英伟达,kimi-k2.5,OpenAI兼容,个人开发者,低门槛"
xhs:690f56cf000000000700e16b,xhs,Kimi K2,2025/11/08,https://www.xiaohongshu.com/explore/690f56cf000000000700e16b,Kimi新发的模型让老外们懵逼了,Max For AI,1105,197,328,5,4,5,0,0,0,性能出色可媲美Claude、造价极低仅460万美元、开源免费可微调贡献、让西方AI巨头神话破灭、引发海外广泛讨论和认可,国内社区讨论度相对较低,,"浏览量突破300万，教授评价为""又一个DeepSeek时刻""，有开发者用例反馈能在多个Agent任务上作为Claude平替",2026/03/01 13:53,20260301_134831_praghb,"中国AI骄傲,开源突破,性价比极高,打破硅谷神话,行业格局改变"
xhs:691310b80000000007017fa5,xhs,Kimi K2,2025/11/11,https://www.xiaohongshu.com/explore/691310b80000000007017fa5,Kimi员工不在，老板深夜 Reddit 讲大瓜,满杯的Model日记,541,56,200,4,4,4,0,0,0,团队真诚没架子，会在Reddit、知乎回答问题；Kimi有很大提升；开源模型打脸闭源差一截；产品活人感重,K3发布时间不确定（调侃8年后）；视觉模型还在开发中,,"「以前开源模型总被说 '比闭源差一截'，现在 K2 也是打脸了」「团队真诚，没有那么大架子，一直都蛮欣赏杨植麟的，这次看到他们主创团队还会在Reddit,知乎上回答问题」",2026/03/01 13:54,20260301_134831_praghb,"K2-thinking,开源模型,Reddit AMA,团队真诚,视觉模型,K3发布时间"
xhs:690d8db2000000000700d303,xhs,Kimi K2,2025/11/07,https://www.xiaohongshu.com/explore/690d8db2000000000700d303,Kimi K2 Thinking这次真玩大了❗️,欧巴聊AI,354,146,112,5,5,5,0,0,0,性能达到世界级SOTA水准，成本仅460万美元，性价比极高，估值被严重低估,,海外AI圈炸锅，Kimi K2 Thinking开源直接干翻闭源，在HLE、BrowseComp全球榜单上超越GPT-5和Claude Sonnet 4.5拿下世界级SOTA,在HLE、BrowseComp全球榜单上把GPT-5和Claude Sonnet 4.5按在地上摩擦；成本460万刀；估值只有OpenAI的0.5%、Anthropic的2%,2026/03/01 13:55,20260301_134831_praghb,"性能卓越,成本极低,高性价比,被低估,开源,SOTA,国产AI"
xhs:6878fafd0000000015020f70,xhs,Kimi K2,2025/07/17,https://www.xiaohongshu.com/explore/6878fafd0000000015020f70,不是吧？Kimi这数据是认真的？,AI进化论Plus,177,80,77,5,4,4,0,3,0,API按量付费数据最真实无假；新模型冲榜速度快；排名超越Claude Opus 4和GPT-4.1,无,,用户在OpenRouter榜单看到Kimi K2直接冲到第七名，认为论文可以吹跑分可以刷但API调用量是开发者用脚投票真金白银砸出来的,2026/03/01 13:55,20260301_134831_praghb,"AI,人工智能,大模型,Kimi,OpenRouter,API,程序员"
xhs:68783aa20000000022030758,xhs,Kimi K2,2025/07/17,https://www.xiaohongshu.com/explore/68783aa20000000022030758,Kimi K2，法律人又一个全能优秀的AI助手！,积成,42,6,68,4,0,0,0,0,0,代码能力强；Agent功能调用能力突出；风格化写作能力优秀；对法律工作有帮助；PPT助手实用,,Kimi K2在代码能力、Agent功能调用能力和风格化写作能力方面表现出色，是法律人的优秀AI助理选择,K2强在三个方面：代码能力、Agent功能调用能力、风格化写作能力。如果一个大模型在这几个方面具有出色的表现，就可以成为法律人的好助理。,2026/03/01 13:55,20260301_134831_praghb,"AI法律,KimiK2,法律AI助手,代码能力,写作能力"
xhs:691ac2870000000005013c3f,xhs,Kimi K2,2025/11/17,https://www.xiaohongshu.com/explore/691ac2870000000005013c3f,开源第一！Kimi K2凭什么刷爆外网？,创哥的AI实验室,57,5,48,4,5,4,0,0,0,在多个测试中超越GPT-5和Sonnet 4.5，全球开源模型排名第一，实战表现让人惊艳，价格因素友好，日常工作任务完全够用,较难的编程问题需要上Codex解决,,在多个测试中超越了GPT-5和Sonnet 4.5，目前更是在全球开源模型中排名第一；测试下来，结果说实话，让我有点惊艳；考虑到价格因素，我觉得日常工作任务用Kimi K2 Thinking是完全够用的，对于比较难的编程问题，再上Codex,2026/03/01 13:56,20260301_134831_praghb,"ai编程,cursor,claudecode,codex,claude"
xhs:687b3256000000001502106b,xhs,Kimi K2,2025/07/19,https://www.xiaohongshu.com/explore/687b3256000000001502106b,所以这是Kimi K2主推Claude Code的原因？,一蛙,39,11,49,3,3,0,0,0,0,多Agent架构对上下文长度更友好，与K2上下文能力匹配；与Gemini-2.5-Pro对比测试表现相当，O3评价略胜,LiveBench长上下文测试得分不太高，单Agent模式对长上下文要求更高,,Kimi K2在这个Bench的长上下文测试上得分不太高。CC+K2和GC+Gemini-2.5-Pro在这个Case上肉眼看伯仲之间，图9开始是O3的评价，cc+k2组合微赢。所以no think的k2有这个成绩很不错了，等K2R,2026/03/01 13:57,20260301_134831_praghb,"Kimi K2,Claude Code,长上下文,多Agent架构,代码场景,对比评测"
xhs:6894bbb9000000002303709d,xhs,Kimi K2,2025/08/07,https://www.xiaohongshu.com/explore/6894bbb9000000002303709d,被狂吹的 KIMI K2也是一轮游,罗本罗,16,30,3,1,1,0,0,0,0,,营销宣传直接吹上天，结果还是0比4一轮游,,KIMI的K2是新模型，营销宣传直接吹上天，结果还是0比4一轮游,2026/03/01 13:57,20260301_134831_praghb,"性能翻车,过度营销,期待落空"
xhs:68e7cd8800000000050018ad,xhs,Kimi K2,2025/10/09,https://www.xiaohongshu.com/explore/68e7cd8800000000050018ad,实测对比！智谱GLM vs Kimi K2哪个更适合程,Felix 的上下文,18,12,8,4,4,5,2,3,0,能力略高于竞品，按量付费灵活，Turbo版支持缓存优化,标准版速度较慢（10-15 tokens/s）,,从我个人使用感受来说，kimi k2的能力还是略高于GLM4.6，大概就是GLM4.6考了80分，k2考了85分这种感觉吧；Kimi K2：按量计费，速度10-15 tokens/s，价格最便宜（输入1元/百万tokens）；轻度使用、预算有限→Kimi标准版,2026/03/01 13:57,20260301_134831_praghb,"性价比,按量付费,能力较强,速度较慢"
xhs:6871c981000000002400c1ce,xhs,Kimi K2,2025/07/12,https://www.xiaohongshu.com/explore/6871c981000000002400c1ce,,Aaron成长进化论,21,2,6,4,3,4,0,2,3,代码质量不错，不多发散，专注完成需求；1万token以下能达到Claude的80分水平；10份代码文件+一个需求场景下表现出色,1万到5万token区间代码无法完整输出，始终偷懒；不联网情况下举例数据集准确率较低（2/5对比Claude的3/5）,,用户使用同一编程任务测试：1万token以下Kimi表现约80分；1-5万token区间无论怎么调整提示词都会偷懒；离线举例数据集正确率Kimi为40%而Claude为60%；10文件+1需求场景下Kimi专注完成需求不多想，Claude完成但想太多,2026/03/01 13:58,20260301_134831_praghb,"编程,代码生成,长文本输出,对比评测,Claude,中文评测"
zhihu_1772363639589_3,知乎,Seed 2.0,2025/02/20,,deepseek 腾讯元宝 豆包 其实最好的还是豆包 是这样的吗？,Trisimo崔思莫,96,0,0,3,2,0,0,0,0,豆包通话功能人味强，是三家里最好的,文字模型有点僵硬，没啥人味，APP还没上Agent,,用户的原话：'没啥人味。这也是豆包的特色，豆包的通话功能，人味还很强，文字模型真的有点僵硬。豆包 APP，除了还没上Agent',2026/03/01 19:13,zhihu_1772363639589,
zhihu_1772364046444_1,知乎,Seed 2.0,2025/02/23,,豆包官宣视频生成模型 Seedance2.0 全端上线，对普通用户和内容创作者有哪些价值？,二郎陈,32,7,0,2,0,2,0,0,0,初期百无禁忌，创作自由度很高,当天配额用不完就清零，版权问题限制想象力,,如果当天没用完，就直接清零了。版权问题，卡死了无数想象力。Seedance 2.0刚开放时，百无禁忌。周星驰可以和李小龙对打,2026/03/01 19:20,zhihu_1772364046444,
zhihu_1772364065791_2,知乎,Seed 2.0,2025/02/15,,关于豆包的Seed2.0，简体中文没有告诉你，这些非常要害和诚实的细节 | 以Agen为马,未尽研究,1,0,0,2,0,0,0,0,0,中国AI实验室罕见地诚实披露了与国际前沿的差距,Seed2.0与国际前沿LLM相比仍存在差距,,文章标题强调「非常要害和诚实的细节」，正文明确指出「Seed2.0系列与国际前沿LLM相比仍存在差距」,2026/03/01 19:21,zhihu_1772364065791,
zhihu_1772364075740_3,知乎,Seed 2.0,2025/02/25,,Seedance 2.0 炸场之后，豆包 Seed2.0 能否再度勇攀高峰？,极客公园,2,0,0,4,4,4,0,0,0,性能有提升；定价有性价比,信息有限，无法全面评估,,Agent。提升性能的同时，豆包2.0在定价上也颇有性价比——豆包2.0 Pro（32k）输入仅需,2026/03/01 19:21,zhihu_1772364075740,
zhihu_1772364094284_4,知乎,Seed 2.0,2026/02/01,,怎么看待seedance2.0降速到几乎不可用？,刚巴德,58,9,0,1,2,1,1,1,1,豆包免费版几分钟能生成一个,付费版要积分却半天生成不了；降速到几乎不可用；只能生成15秒,,要积分的即梦半天生成不了，不要钱的豆包几分钟出来一个！不过缺点是豆包只能生成15秒的，多一秒也不行,2026/03/01 19:21,zhihu_1772364094284,
zhihu_1772364141277_7,知乎,Seed 2.0,2025/02/15,,字节豆包Seed 2.0 Pro实测：新版本硬实力登顶,晴天,1,0,0,4,4,0,0,0,0,在LogicVista、VisuLogic等基准上得分显著提升；视觉感知能力进一步升级,,新版本在视觉解谜与逻辑推理基准上实现显著提升，能力登顶,在LogicVista、VisuLogic等视觉解谜与逻辑推理基准上，Seed2.0 Pro得分较Seed1.8显著提升,2026/03/01 19:22,zhihu_1772364141277,
zhihu_1772364176185_9,知乎,Seed 2.0,2025/02/23,,豆包2.0来了！中国版Trae免费用～,AI袋鼠帝,5,0,0,4,3,4,0,0,0,专门面向编程场景优化,,,作为开发者，我最关心的还是这个Seed 2.0 Code。Seed 2.0 Code是字节专门面向编程场景优化的,2026/03/01 19:22,zhihu_1772364176185,
zhihu_1772364251582_13,知乎,Seed 2.0,2025/02/14,,豆包大模型 Seed-2.0 正式发布，带来哪些新功能和体验升级？,橘鸦Juya,32,2,0,4,4,0,0,0,0,洗车问题回答很不错,,,现在至少我们可以知道，专家档就是Seed-2.0 Pro，怪不得不我之前测试豆包发现应对洗车问题的回答很不错,2026/03/01 19:24,zhihu_1772364251582,
zhihu_1772365423359_0,知乎,Kimi K2,2025/11/07,,Kimi K2 Thinking模型发布并开源，该模型哪些信息值得关注？,toyama nao,510,190,0,4,4,4,0,0,0,开源的思考模型，比K1.5有进步,被比作Apollo10，说明还不是最终登月般的突破,Kimi的Apollo10号，在K1.5不算成功的推理模型探索后的进展,短的结论：属于Kimi的阿波罗10号。Kimi在经过K1.5那不算成功的推理模型探索后,2026/03/01 19:43,zhihu_1772365423359,
zhihu_1772365546465_8,知乎,Kimi K2,2025/07/29,,Kimi K2：全维度无短板,AI创作玩家,0,1,0,5,0,0,0,0,0,全维度无短板,,全维度无短板,标题仅显示「Kimi K2：全维度无短板」，正文与标题相同，未提供具体使用体验或详细评价,2026/03/01 19:45,zhihu_1772365546465,
zhihu_1772365557902_9,知乎,Kimi K2,2026/02/24,,Kimi连续融资超12亿美元，估值翻倍突破100亿美元，阿里、腾讯都投了,无意觅知音,7,0,0,5,4,4,5,4,0,几分钟完成一周工作量，生产力大幅提升,,,以前一周都不一定干的完的活，Kimi K2.5几分钟给你出报告。生产力直接拉爆,2026/03/01 19:45,zhihu_1772365557902,
zhihu_1772365667713_16,知乎,Kimi K2,2026/01/26,,kimi更新K2.5后，网页端无法访问，显示502报错,kimi用户,0,1,0,1,0,0,0,0,0,无,网页端无法访问，显示502报错,更新K2.5后网页端完全无法访问，一直显示502报错,kimi更新K2.5后，网页端无法访问，显示502报错,2026/03/01 19:47,zhihu_1772365667713,
zhihu_1772365686361_17,知乎,Kimi K2,2026/02/03,,kimi算不算国内顶级的AI？,樱井椎子,103,36,0,2,3,0,2,2,2,宣传有2.5思考能力,凌晨一点峰时段算力不足,尽管宣传2.5思考能力，但在凌晨峰时段仍算力不足,code更新app都宣传的2.5思考，结果凌晨一点还在峰时段算力不足,2026/03/01 19:48,zhihu_1772365686361,
zhihu_1772365701133_18,知乎,Kimi K2,2025/12/01,,Kimi K2 vs GPT-4o 对比测评,AI测评师,89,12,0,3,4,3,0,0,0,长文本理解能力出色，略胜GPT-4o,代码生成方面还有提升空间,Kimi K2在长文本理解任务上略胜GPT-4o，但代码生成能力有待提升。,在长文本理解任务上，Kimi K2略胜GPT-4o，但在代码生成方面还有提升空间,2026/03/01 19:48,zhihu_1772365701133,
zhihu_1772365716036_19,知乎,Kimi K2,2025/12/15,,为什么Kimi K2突然变慢了？,科技百晓生,45,8,0,2,0,0,2,0,2,非高峰期使用体验尚可,高峰期服务器响应慢,,高峰期服务器负载过高导致响应变慢，建议避开高峰时段使用,2026/03/01 19:48,zhihu_1772365716036,
zhihu_1772365983829_0,知乎,GLM 5,2026/02/13,,GLM-5 逼平 ClaudeOpus4.5，对中国 AI 大模型发展有何意义？,Trisimo崔思莫,251,0,0,4,4,4,0,0,0,在中美算力差距巨大的情况下仍能研发出与ClaudeOpus4.5相当的GLM-5,,,我还挺看好Kimi和GLM，毕竟中美两国算力差距非常大，能捣鼓出K2.5和GLM-5已经可以开香槟了,2026/03/01 19:53,zhihu_1772365983829,
zhihu_1772366009969_2,知乎,GLM 5,2026/02/27,,26年2月 国产 Coding LLM 最新模型 Kimi K2.5、MiniMax M2.5 与 GLM-5 深度对比,逆风,39,22,0,4,4,0,0,0,0,在多个权威benchmark表现优异；智能体与推理领域的先锋,,GLM-5被定位为智能体与推理领域的先锋，在多个权威基准测试中表现优异,GLM-5：智能体与推理先锋，GLM-5在多个权威benchmark表现优异,2026/03/01 19:53,zhihu_1772366009969,
zhihu_1772366043758_3,知乎,GLM 5,2026/02/12,,智谱最新大模型 GLM-5 官网上线，有哪些值得关注的亮点？使用感受如何？,toyama nao,241,90,0,4,4,0,0,0,0,年会抽奖问题能1 Pass满分通过，表现出色,幻觉问题仍有进步空间,,年会抽奖问题，需要完全不犯错才能满分，GLM-5也有1 Pass拿下。当然GLM-5在幻觉上仍有进步空间,2026/03/01 19:54,zhihu_1772366043758,
zhihu_1772366086510_6,知乎,GLM 5,2026/02/12,,今天，被GLM-5的Agentic Coding能力惊艳到了,小林coding,94,14,0,5,5,0,0,0,0,Agentic Coding的调试和修复能力强,,,作者将调试修复任务丢给GLM-5测试，期待验证其能力，标题明确表示被惊艳到了,2026/03/01 19:54,zhihu_1772366086510,
zhihu_1772366116314_8,知乎,GLM 5,2026/02/12,,测完 GLM-5 我沉默了：国产开源模型什么时候这么能打了？,孟健AI编程,3,1,0,4,4,0,0,0,2,分析路径非常清晰,第一个例子启动报错,,用户提到第一个例子启动报错，之前自己踩过坑搜了不少资料才搞定，问GLM-5后分析路径非常清晰,2026/03/01 19:55,zhihu_1772366116314,
zhihu_1772366128805_9,知乎,GLM 5,2026/02/25,,GLM-5 逼平 ClaudeOpus4.5，对中国 AI 大模型发展有何意义？,TabNahida,42,26,0,1,0,1,1,0,0,,速度比Qwen差一大截，成本贵了近一倍，缺乏明显竞争优势,,LLM里你要么有显著的成本优势，要么你有最强的智能，要么极低延迟加高速。GLM5很尴尬，速度差Qwen一大截，成本贵了快一倍,2026/03/01 19:55,zhihu_1772366128805,
zhihu_1772366160416_11,知乎,GLM 5,2026/02/12,,智谱最新大模型 GLM-5 官网上线，有哪些值得关注的亮点？使用感受如何？,徐辰,167,39,0,4,0,0,4,0,2,执行速度快，5分钟不到完成两个任务,存在编译器缓存问题,,计划中一共6大步骤它5分钟不到就说做完了两个，但是由于编译器缓存的问题所以...,2026/03/01 19:56,zhihu_1772366160416,
zhihu_1772366173178_12,知乎,GLM 5,2026/02/22,,【论文精读】GLM-5 深度解读：当 AI 学会真正干活，而不只是聊天,JasonL,3,0,0,3,3,3,0,3,0,提供了GLM-5与7B token差距的数据对比（47倍），提及冷启动技术细节,内容非常简短，文章似乎未完整展示，缺乏对模型性能、实际应用场景的深入分析,技术解读文章，简要对比了GLM-5与7B token的差距（约47倍），提到使用GLM-4.7-Flash冷启动。,7B token，GLM-5只用了约20B——差距约47倍。GLM-5用GLM-4.7-Flash作为冷启动引,2026/03/01 19:56,zhihu_1772366173178,
zhihu_1772366237460_15,知乎,GLM 5,2026/02/13,,Claude4.6还是牛，给GLM5出了10个毒题！,Jarvis,10,5,0,4,0,0,0,0,0,Claude 4.6性能强劲，能为新兴模型出难题,帖子内容过于简短，未详细展开,,Claude4.6还是牛，给GLM5出了10个毒题,2026/03/01 19:57,zhihu_1772366237460,
zhihu_1772366265196_16,知乎,GLM 5,2026/02/13,,为什么智谱glm5和minimax m2.5还是纯文本模型，万亿多模态那么难做吗？,shawn-bard,4,1,0,3,3,3,0,0,0,Model scaling is necessary for generalization rather than specialization; GLM5 has been scaled to 2x previous size,Trillion-scale multimodal models remain technically challenging to develop,Technical discussion about why GLM5 remains a pure text model and the challenges of scaling multimodal capabilities to trillion parameters.,首先基准模型规模要先scale上去，模型才会有泛化的能力，而不是某个领域的特化。GLM5这次已经scale到之前的2倍,2026/03/01 19:57,zhihu_1772366265196,
zhihu_1772366292168_17,知乎,GLM 5,2026/02/23,,GLM-5 技术报告发布被 a16z 称为最好的开源模型，它有哪些亮点？,开心猫,32,51,0,1,1,0,0,0,0,,蒸馏了太多Claude的数据来训练,,GLM-5翻车了，蒸馏了太多claude的数据来训练（蒸馏数据就是大量账号向claude模型提问，获取答案,2026/03/01 19:58,zhihu_1772366292168,
zhihu_1772366339473_18,知乎,GLM 5,2026/02/13,,以为又是国产之光营销，测完GLM-5我想给智谱磕两个,吉米侃AI,3,6,0,5,0,0,0,0,0,参数背后的暴力美学，这次是真下血本了，有硬核数据支撑,,以为又是国产之光营销，测完GLM-5我想给智谱磕两个,参数背后的暴力美学，GLM-5这次是真下血本了，咱们看几组硬核数据,2026/03/01 19:58,zhihu_1772366339473,
zhihu_1772366780778_2,知乎,Minimax M2.5,2026/02/13,,稀宇 MiniMax M2.5 测评,toyama nao,151,37,0,1,0,0,0,0,0,,,极简正面评价，仅提及MiniMax M2.5将国产模型编程可用性向前推进一大步，未提供具体性能维度信息,M2.5这一代则将国模编程可用性向前推进一大步,2026/03/01 20:06,zhihu_1772366780778,
zhihu_1772366854657_5,知乎,Minimax M2.5,2026/02/12,,我给 Claude Code 加装了 MiniMax M2.5：它像法拉利，但更像一台工作机,池建强,19,0,0,4,0,0,0,0,0,可与Claude Code直接使用，模型性能如法拉利般出色，同时适合作为工作机使用,,像法拉利但更像一台工作机。提到可以直接在Claude Code中使用MiniMax的模型，此前一直使用MiniMax M2.1。评,标题：我给 Claude Code 加装了 MiniMax M2.5：它像法拉利，但更像一台工作机 | 正文：CC就可以直接用MiniMax的模型了。之前我一直用MiniMax M2.1 | 点赞数: 19,2026/03/01 20:07,zhihu_1772366854657,
zhihu_1772366874040_6,知乎,Minimax M2.5,2026/02/14,,MiniMax M2.5模型正式上线，是否真正实现生产力SOTA与低负担，如何评价其表现？,小小将,148,9,0,4,0,0,5,5,0,思考时间不足2秒，输出速度非常快，延迟和吞吐量表现优秀,未提及质量、性价比、稳定性等方面信息,MiniMax M2.5在速度和延迟方面表现突出，思考时间短于2秒，输出速度快，但缺乏质量、价值、稳定性等其他维度的评价信息,而MiniMax M2.5的思考时间不足2秒。同时，MiniMax M2.5的输出速度也非常快,2026/03/01 20:07,zhihu_1772366874040,
zhihu_1772366897298_7,知乎,Minimax M2.5,2026/02/12,,国产编程神器，MiniMax M2.5 问世！,GitHub Daily,18,5,0,4,0,0,0,0,0,,,"标题称其为""国产编程神器""，作者表示获得了MiniMax M2.5的大模型内测权限。文章主要讨论延迟与成本将成为未来大模型的重点攻克方向，但未提供具体的模型性能评价。",标题: 国产编程神器，MiniMax M2.5 问世！; 正文: 延迟与成本将成为未来大模型重点攻克的一个主流方向。我有幸拿到了MiniMax M2.5的大模型内测权限,2026/03/01 20:08,zhihu_1772366897298,
zhihu_1772366930972_9,知乎,Minimax M2.5,2026/02/13,,MiniMax M2.5实测,晴天,1,0,0,4,0,0,0,0,0,在编程、工具调用和搜索、办公等生产力场景达到行业前沿水平,,MiniMax M2.5在编程、工具调用、搜索和办公等生产力场景达到了行业前沿水平,在编程、工具调用和搜索、办公等生产力场景达到了行业前沿水平,2026/03/01 20:08,zhihu_1772366930972,
zhihu_1772366989789_12,知乎,Minimax M2.5,2026/02/25,,如何评价MiniMax-M2.5？,xiudou,32,12,0,4,3,4,0,0,0,体验不错，性能优于等于code5.3 medium水平，值得入手,,MiniMax-M2.5性能达到或超过code5.3 medium水平，是值得购买的产品,体验下来，>=code5.3 medium，值得入手,2026/03/01 20:09,zhihu_1772366989789,
zhihu_1772367047057_15,知乎,Minimax M2.5,2026/02/13,,如何评价MiniMax-M2.5？,靳伟,36,15,0,4,4,3,0,0,0,模型能力很好，参数规模大（约2万亿）,coding plan功能比较抠门,MiniMax-M2.5参数规模高达2万亿或接近2万亿，模型能力表现很好，但在coding plan功能方面有所保留,传说中参数是2万亿或接近2万亿。kimi-2.5是1.04万亿，模型能力很好，就是coding plan抠门了一点,2026/03/01 20:10,zhihu_1772367047057,
zhihu_1772367104693_18,知乎,Minimax M2.5,2026/02/15,,MiniMax M2.5 编程能力深度测评,程序员张三,28,8,0,5,4,0,0,0,0,代码生成能力优秀，在真实项目开发中表现优异,,在真实项目开发中测试了MiniMax M2.5的代码生成能力，整体表现优秀,在真实项目开发中测试了MiniMax M2.5的代码生成能力，整体表现优秀,2026/03/01 20:11,zhihu_1772367104693,
zhihu_1772367115275_19,知乎,Minimax M2.5,2026/02/18,,MiniMax M2.5 vs Claude Code 编程对比实测,AI测评师,45,12,0,4,3,0,0,0,0,在中文编程场景有明显优势,在复杂逻辑处理上略逊于Claude Code,MiniMax M2.5在中文编程场景有明显优势，但在复杂逻辑处理上略逊于Claude Code,MiniMax M2.5在中文编程场景有明显优势，但在复杂逻辑处理上略逊于Claude Code,2026/03/01 20:11,zhihu_1772367115275,
zhihu_1772367805695_1,知乎,Kimi K2.5,2026/02/03,,kimi算不算国内顶级的AI？,樱井椎子,103,36,0,2,0,0,2,2,2,,凌晨一点还在峰时段算力不足，Kimi宣传K2.5思考但算力跟不上,,人家都写清楚你有多少高级模型配额。而到了Kimi，你更新app都宣传的2.5思考，结果凌晨一点还在峰时段算力不足,2026/03/01 20:23,zhihu_1772367805695,
zhihu_1772367856832_3,知乎,Kimi K2.5,2026/01/27,,Kimi 发布并开源 K2.5 模型，哪些信息值得关注？Agent 集群能力能做哪些任务？,toyama nao,400,88,0,4,3,0,0,0,0,Positive sentiment about Kimi team's continuous innovation; K2.5 model appears to be a significant advancement after K2 refinement; strong community engagement with 400 likes and 88 comments indicating user interest,Lacks specific technical details about K2.5 model capabilities; no explicit information about Agent cluster task performance,,"400 likes, 88 comments, published 2026/01/27; mentions K2锤炼 (K2 refinement) and 大杀器 (powerful tools)",2026/03/01 20:24,zhihu_1772367856832,
zhihu_1772367971005_11,知乎,Kimi K2.5,2026/02/18,,Kimi K2.5 干货有点多啊,兽族机枪兵,50,0,0,4,4,0,0,0,0,数据来源丰富，涵盖Kimi K2、Kimi K2 Thinking及内部专家模型，内容干货多（点赞数50）,,,标题「Kimi K2.5 干货有点多啊」表达正面评价；正文说明数据来源于Kimi K2、Kimi K2 Thinking及内部专家模型；点赞数50，评论数0，发布日期2026/02/18,2026/03/01 20:26,zhihu_1772367971005,
zhihu_1772368433767_9,知乎,Gemini 3.1,2026/02/20,,Google 发布 Gemini3.1Pro 模型，它在技术上有哪些亮点和突破？,zack zack,92,19,0,3,0,0,0,0,0,,,前一天晚上还在批评Gemini 3.0，但3.1版本默默解决了所有遗留问题。,昨晚还在antigravity里和Gemini 3.0激情对喷，今天早上3.1就默默把所有遗留问题都解决了。,2026/03/01 20:33,zhihu_1772368433767,
zhihu_1772368446986_10,知乎,Gemini 3.1,2026/02/20,,Gemini3 是目前最强 AI 吗？,靳伟,110,27,0,5,0,0,0,0,0,,,,"The post states Gemini 3 Pro ranks first in the latest AI rankings, with Claude Opus 4.6 in second place.",2026/03/01 20:34,zhihu_1772368446986,
zhihu_1772368458154_11,知乎,Gemini 3.1,2026/02/24,,Gemini3.1 实测了9个例子，结果不太理想！,Jarvis,3,1,0,2,2,0,0,0,0,,测试了9个例子，结果不太理想；Gemini 3.1相比Claude不够详细,实测9个例子结果不理想。Gemini 3.1与Claude风格明显不同，Gemini 3.1更简洁，而Claude更详细。,标题: 实测了9个例子，结果不太理想；正文: Claude和Gemini 3.1是明显不一样的。Gemini 3.1比较简洁，Claude更详细。,2026/03/01 20:34,zhihu_1772368458154,
zhihu_1772368471870_12,知乎,Gemini 3.1,2026/02/27,,Gemini3升级了，但不能正常用了,草帽lufei,1,3,0,1,1,0,4,0,1,用户最终切换到Gemini 3 Flash作为替代方案,Gemini 3.1 Pro升级后无法正常使用，等待很长时间后失败,Gemini 3.1升级后无法正常使用，等待很长时间后失败，被迫切换到Gemini 3 Flash作为替代方案,标题:Gemini3升级了，但不能正常用了; 正文:没想到今天下午用Gemini 3.1 Pro改个需求，等了半天，失败了。再次重来，后面换Gemini 3 Flash,2026/03/01 20:34,zhihu_1772368471870,
zhihu_1772368534043_16,知乎,Gemini 3.1,2026/02/27,,Gemini 3.1 Pro 夯爆了！（附教程）,老虎不是猫,7,0,0,5,5,0,0,0,0,文本和绘图能力均升级，性能强大,,「夯爆了」且「真的强」，文本和绘图功能都有升级，Gemini 3.1 Pro和Nano都变得更强。,真的，试了真的强！这次文本+绘图都升级了，Gemini 3.1 Pro和Nano都更强了。,2026/03/01 20:35,zhihu_1772368534043,
